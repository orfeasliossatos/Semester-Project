{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "Convolutional neural networks learn to separate noisy images from structured images with less training examples than fully connected neural networks.\n",
    "\n",
    "## Measurement\n",
    "\n",
    "We will measure the gap between the two models in the number of training examples required to exceed an accuracy of $\\epsilon$ as a function of the side length $L$ of the image.\n",
    "\n",
    "## Training Data\n",
    "\n",
    "Generating the labels in $\\{0, 1\\}$:\n",
    "+ $Y\\sim \\text{Bernoulli}(p)$ with parameter $p=0.5$.\n",
    "\n",
    "Generating one image : \n",
    "+ Create Fourier-domain square image $\\dot{X}$ of side length $L$. \n",
    "\n",
    "+ In a low pass box of side-length $L/2$, set between $1$ and $K\\leq (L/2)^2$ random points to a random number on the complex unit circle, leaving the rest with amplitude $0$.\n",
    "\n",
    "+ Then $|IFT(\\dot{X})|$ with pixel-wise modulus corresponds to images with regular wave patterns, such as stripes or checkerboards.\n",
    "\n",
    "+ We standardize $|IFT(\\dot{X})|$ such that the average pixel value is 0 and variance of pixel values is 1, and call it $M$.\n",
    "\n",
    "+ If the label is $1$, obfuscate $M$ with Gaussian noise sampled independently at every pixel $Z\\sim \\mathcal{N}(0, 1)$:\n",
    "$$X = M + YZ$$\n",
    "\n",
    "+ Then L1-normalize and scale by $L^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import product\n",
    "from helpers import *\n",
    "from models import ModelLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings\n",
    "There are multiple variables associated with this experiment.\n",
    "+ The data\n",
    "    + The range of image sizes to test \n",
    "        + We test $L\\in[10, 40]$ in steps of $2$ for no spiky results (due to stride $2$ max-pooling)\n",
    "    + Distinct frequency count $\\leq K=8$\n",
    "\n",
    "+ The model architectures\n",
    "    + Convolutional neural network (CNN)\n",
    "        + Convolutional layer : $1$ in channel, $1000$ out channels, kernel size $3$, stride $1$, padding $1$\n",
    "        + Activation layer : ReLU\n",
    "        + Max pool layer : kernel size $2$, stride $2$\n",
    "        + Linear layer : _ in, $1$ out neuron\n",
    "        + Sigmoid layer\n",
    "    + Fully connected neural network (FCNN)\n",
    "        + Linear layer : $L^2$ in, $P$ out neurons\n",
    "        + Activation layer : ReLU\n",
    "        + Linear layer : $P$ in, $1$ out neuron\n",
    "        + Sigmoid layer\n",
    "            + The first linear layer has $PL^2$ weights, the second has $P$ weights. So the FCNN has about $P(L^2+1)$ parameters.\n",
    "            + We set $P$ so that the FCNN matches the CNN in terms of raw parameter count. \n",
    "            + If the CNN has $Q$ parameters, then let $P=\\max\\{1, Q / (L^2+1)\\}$\n",
    "+ The learning protocol\n",
    "    + Adam\n",
    "    + Batch-size $64$\n",
    "    + Accuracy goal $\\epsilon \\in \\{0.95\\}$\n",
    "    + Learning rate $0.0001$ for CNN, $0.005$ for FCNN.\n",
    "    + Generate new batches of images online.\n",
    "+ The testing protocol\n",
    "    + Set training loss goal to $0.5$. If the model passes the goal, then test on set of $1000$ fixed images (making sure to reset gradients) and compute accuracy $\\alpha$.\n",
    "    + If the obtained accuracy surpasses the requirement $\\alpha > \\epsilon$, then stop. otherwise, lower the training loss goal by $0.025$ and continue training on new batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment variables\n",
    "min_w           = 10 # Minimum image width\n",
    "max_w           = 40 # Maximum image width\n",
    "skip_w          = 2 # Skip widths\n",
    "delete          = False # Delete results of previous runs for that model.\n",
    "relative        = True # The box scales with the image size\n",
    "balance         = False # Balance the results of the previous runs in case of stopping\n",
    "architecture    = \"FCNN\" \n",
    "activation      = \"ReLU\"\n",
    "arch_name       = architecture + \"+\" + activation\n",
    "learning_rate   = 0.005\n",
    "cnn_out_chans   = 1000\n",
    "batch_size      = 64\n",
    "N_te            = 1_000   # Test set\n",
    "epsilon         = 0.75     # Required accuracy\n",
    "freq            = 8       # Max number of distinct frequencies            \n",
    "clamp           = 8       # Frequency band clamp\n",
    "estimates       = 3\n",
    "filepath        = 'results/week8/acc'+str(int(epsilon * 100))+('rel' if relative else 'freq'+str(freq)+'clamp'+str(clamp))+'.pkl' # Results file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file if it doesn't exist\n",
    "with open(filepath, 'ab+') as file:\n",
    "    if os.stat(filepath).st_size == 0:\n",
    "        pickle.dump(dict(), file)\n",
    "\n",
    "# Option del - delete contents of results file\n",
    "if delete:\n",
    "    with open(filepath, 'rb+') as file:\n",
    "        results = pickle.load(file)\n",
    "\n",
    "    # Filter out results with same name\n",
    "    with open(filepath, 'wb+') as file:\n",
    "        filtered = {(name, size) : val for (name, size), val in results.items() if name!=arch_name}\n",
    "        pickle.dump(filtered, file)\n",
    "\n",
    "# Option balance - balance previous results\n",
    "if balance:        \n",
    "    with open(filepath, 'rb+') as file:\n",
    "        results = pickle.load(file)\n",
    "\n",
    "        # The minumum number of runs from previous\n",
    "        min_runs = min([len(res) for (name, size), res in results.items() if name==arch_name])\n",
    "\n",
    "    # Filter out results with same name\n",
    "    with open(filepath, 'wb+') as file:\n",
    "        balanced = {(name, size): res[:min_runs] if name==arch_name else res for (name, size), res in results.items()}\n",
    "        pickle.dump(balanced, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cpu \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device, \"\\n\")\n",
    "\n",
    "# Don't try to use CuDNN with Tesla GPU\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "# GPU has not a lot of memory, so empty cache\n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "# Avoid fragmentation\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pattern_xy(width, channels, number, max_freq, clamp):\n",
    "\n",
    "    # Choose a number of frequencies\n",
    "    freqs = np.arange(1, max_freq+1)\n",
    "    freq = np.random.choice(a=freqs, p=freqs / np.sum(freqs))\n",
    "\n",
    "    # Bernoulli labels : noise / no noise\n",
    "    sigs = np.random.choice([0, 1], size=(number, ), p=[0.5, 0.5])\n",
    "    y = np.where(sigs == 0, 0, 1)\n",
    "\n",
    "    # Blank F-domain canvases [number, channels, width, height]\n",
    "    blank = np.zeros(width * width).astype(complex)\n",
    "    f_dom = blank.reshape((1,len(blank))).repeat(number, axis=0).reshape((number, channels, width, width))\n",
    "\n",
    "    # Select random pixels in low frequency box\n",
    "    span = np.arange(-clamp//2, clamp//2+1)         # Index [-clamp, clamp] along one dimension\n",
    "    w, h = list(zip(*list(product(span, span))))    # The pairs of indices in two dimensions unzipped\n",
    "    subarray = f_dom[..., w, h]                \n",
    "    subarray[..., :freq] = np.exp(2 * np.pi * 1j * np.random.rand(number, channels, freq)) # Set some capped number of pixels to 1 in the box\n",
    "    permute_along_axes(subarray, [2])               # Randomize the position of those pixels \n",
    "    f_dom[..., w, h] = subarray                     # Assign the original image with those pixels\n",
    "\n",
    "    # Perform the 2D inverse Fourier transform\n",
    "    x_dom = np.array([standardize(img) for img in np.abs(np.fft.ifft2(f_dom))])\n",
    "\n",
    "    # Add noise depending on the label\n",
    "    x_dom = np.array([x_dom[j] + np.random.normal(0, sigs[j], size=(channels, width, width)) for j in range(number)])\n",
    "\n",
    "    # Convert to torch tensors\n",
    "    x_dom = torch.from_numpy(x_dom).to(torch.float32)\n",
    "    y = torch.from_numpy(y.reshape((-1,1))).to(torch.float32)\n",
    "\n",
    "    # L1-normalize the image\n",
    "    x_dom *= width**2 / (x_dom.norm(p=1, dim=[2,3], keepdim=True)  + 1e-6)\n",
    "\n",
    "    return x_dom, y, f_dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image width: 10\n",
      "Generating test data\n",
      "Number of hidden_neurons 346\n",
      "Generated FCNN with 35293 parameters\n",
      "Current accuracy: 0.626\n",
      "Current accuracy: 0.7\n",
      "Current accuracy: 0.77\n",
      "Reached accuracy: 0.77 in 276 batches of size 64.\n",
      "Progress: 1 / 16\n",
      "Image width: 12\n",
      "Generating test data\n",
      "Number of hidden_neurons 317\n",
      "Generated FCNN with 46283 parameters\n",
      "Current accuracy: 0.708\n",
      "Current accuracy: 0.696\n",
      "Current accuracy: 0.715\n",
      "Current accuracy: 0.722\n",
      "Current accuracy: 0.72\n",
      "Current accuracy: 0.73\n",
      "Current accuracy: 0.769\n",
      "Reached accuracy: 0.769 in 479 batches of size 64.\n",
      "Progress: 2 / 16\n",
      "Image width: 14\n",
      "Generating test data\n",
      "Number of hidden_neurons 299\n",
      "Generated FCNN with 59203 parameters\n",
      "Current accuracy: 0.612\n",
      "Current accuracy: 0.639\n",
      "Current accuracy: 0.631\n",
      "Current accuracy: 0.715\n",
      "Current accuracy: 0.729\n",
      "Current accuracy: 0.739\n",
      "Current accuracy: 0.762\n",
      "Reached accuracy: 0.762 in 563 batches of size 64.\n",
      "Progress: 3 / 16\n",
      "Image width: 16\n",
      "Generating test data\n",
      "Number of hidden_neurons 287\n",
      "Generated FCNN with 74047 parameters\n",
      "Current accuracy: 0.551\n",
      "Current accuracy: 0.656\n",
      "Current accuracy: 0.702\n",
      "Current accuracy: 0.675\n",
      "Current accuracy: 0.721\n",
      "Current accuracy: 0.719\n",
      "Current accuracy: 0.731\n",
      "Current accuracy: 0.731\n",
      "Current accuracy: 0.781\n",
      "Reached accuracy: 0.781 in 842 batches of size 64.\n",
      "Progress: 4 / 16\n",
      "Image width: 18\n",
      "Generating test data\n",
      "Number of hidden_neurons 280\n",
      "Generated FCNN with 91281 parameters\n",
      "Current accuracy: 0.536\n",
      "Current accuracy: 0.637\n",
      "Current accuracy: 0.619\n",
      "Current accuracy: 0.656\n",
      "Current accuracy: 0.711\n",
      "Current accuracy: 0.77\n",
      "Reached accuracy: 0.77 in 859 batches of size 64.\n",
      "Progress: 5 / 16\n",
      "Image width: 20\n",
      "Generating test data\n",
      "Number of hidden_neurons 274\n",
      "Generated FCNN with 110149 parameters\n",
      "Current accuracy: 0.516\n",
      "Current accuracy: 0.568\n",
      "Current accuracy: 0.643\n",
      "Current accuracy: 0.657\n",
      "Current accuracy: 0.686\n",
      "Current accuracy: 0.683\n",
      "Current accuracy: 0.683\n",
      "Current accuracy: 0.732\n",
      "Current accuracy: 0.737\n",
      "Current accuracy: 0.755\n",
      "Reached accuracy: 0.755 in 1154 batches of size 64.\n",
      "Progress: 6 / 16\n",
      "Image width: 22\n",
      "Generating test data\n",
      "Number of hidden_neurons 270\n",
      "Generated FCNN with 131221 parameters\n",
      "Current accuracy: 0.531\n",
      "Train loss: 1.0291788578033447\n",
      "Current accuracy: 0.601\n",
      "Current accuracy: 0.661\n",
      "Current accuracy: 0.676\n",
      "Current accuracy: 0.67\n",
      "Current accuracy: 0.688\n",
      "Current accuracy: 0.743\n",
      "Current accuracy: 0.757\n",
      "Reached accuracy: 0.757 in 1442 batches of size 64.\n",
      "Progress: 7 / 16\n",
      "Image width: 24\n",
      "Generating test data\n",
      "Number of hidden_neurons 266\n",
      "Generated FCNN with 153749 parameters\n",
      "Current accuracy: 0.546\n",
      "Train loss: 1.0062882900238037\n",
      "Current accuracy: 0.618\n",
      "Current accuracy: 0.673\n",
      "Current accuracy: 0.646\n",
      "Current accuracy: 0.657\n",
      "Current accuracy: 0.709\n",
      "Current accuracy: 0.732\n",
      "Current accuracy: 0.618\n",
      "Train loss: 2.234107494354248\n",
      "Current accuracy: 0.735\n",
      "Current accuracy: 0.746\n",
      "Train loss: 2.126014471054077\n",
      "Current accuracy: 0.736\n",
      "Train loss: 2.140799045562744\n",
      "Current accuracy: 0.774\n",
      "Reached accuracy: 0.774 in 2254 batches of size 64.\n",
      "Progress: 8 / 16\n",
      "Image width: 26\n",
      "Generating test data\n",
      "Number of hidden_neurons 264\n",
      "Generated FCNN with 178993 parameters\n",
      "Current accuracy: 0.554\n",
      "Current accuracy: 0.547\n",
      "Current accuracy: 0.616\n",
      "Current accuracy: 0.681\n",
      "Current accuracy: 0.687\n",
      "Current accuracy: 0.675\n",
      "Current accuracy: 0.714\n",
      "Current accuracy: 0.678\n",
      "Current accuracy: 0.707\n",
      "Current accuracy: 0.707\n",
      "Current accuracy: 0.738\n",
      "Train loss: 1.9940030574798584\n",
      "Train loss: 2.146055221557617\n",
      "Current accuracy: 0.758\n",
      "Reached accuracy: 0.758 in 2311 batches of size 64.\n",
      "Progress: 9 / 16\n",
      "Image width: 28\n",
      "Generating test data\n",
      "Number of hidden_neurons 262\n",
      "Generated FCNN with 205933 parameters\n",
      "Train loss: 1.040848970413208\n",
      "Train loss: 1.0202113389968872\n",
      "Train loss: 1.0009937286376953\n",
      "Current accuracy: 0.522\n",
      "Current accuracy: 0.542\n",
      "Current accuracy: 0.577\n",
      "Current accuracy: 0.606\n",
      "Current accuracy: 0.607\n",
      "Current accuracy: 0.664\n",
      "Current accuracy: 0.586\n",
      "Current accuracy: 0.664\n",
      "Current accuracy: 0.709\n",
      "Current accuracy: 0.661\n",
      "Train loss: 1.0682013034820557\n",
      "Train loss: 1.9809684753417969\n",
      "Current accuracy: 0.729\n",
      "Current accuracy: 0.741\n",
      "Train loss: 2.067406177520752\n",
      "Train loss: 2.0712671279907227\n",
      "Current accuracy: 0.76\n",
      "Reached accuracy: 0.76 in 2810 batches of size 64.\n",
      "Progress: 10 / 16\n",
      "Image width: 30\n",
      "Generating test data\n",
      "Number of hidden_neurons 260\n",
      "Generated FCNN with 234521 parameters\n",
      "Train loss: 1.1115361452102661\n",
      "Train loss: 1.0705742835998535\n",
      "Train loss: 1.0015617609024048\n",
      "Train loss: 1.072166919708252\n",
      "Train loss: 1.086332082748413\n",
      "Current accuracy: 0.586\n",
      "Current accuracy: 0.631\n",
      "Current accuracy: 0.633\n",
      "Current accuracy: 0.651\n",
      "Current accuracy: 0.666\n",
      "Current accuracy: 0.643\n",
      "Current accuracy: 0.666\n",
      "Current accuracy: 0.711\n",
      "Train loss: 2.087423086166382\n",
      "Current accuracy: 0.695\n",
      "Train loss: 1.1058262586593628\n",
      "Current accuracy: 0.72\n",
      "Current accuracy: 0.737\n",
      "Current accuracy: 0.699\n",
      "Train loss: 2.097778558731079\n",
      "Current accuracy: 0.779\n",
      "Reached accuracy: 0.779 in 3340 batches of size 64.\n",
      "Progress: 11 / 16\n",
      "Image width: 32\n",
      "Generating test data\n",
      "Number of hidden_neurons 259\n",
      "Generated FCNN with 265735 parameters\n",
      "Train loss: 1.1273915767669678\n",
      "Train loss: 1.0044585466384888\n",
      "Train loss: 1.1847015619277954\n",
      "Train loss: 1.061681866645813\n",
      "Train loss: 1.1387755870819092\n",
      "Train loss: 1.1056883335113525\n",
      "Train loss: 1.0926613807678223\n",
      "Train loss: 1.0770949125289917\n",
      "Current accuracy: 0.523\n",
      "Train loss: 1.0485637187957764\n",
      "Train loss: 1.020053744316101\n",
      "Current accuracy: 0.569\n",
      "Train loss: 1.0274388790130615\n",
      "Train loss: 1.1054223775863647\n",
      "Train loss: 1.0174431800842285\n",
      "Current accuracy: 0.569\n",
      "Train loss: 1.0672345161437988\n",
      "Current accuracy: 0.645\n",
      "Train loss: 1.0176690816879272\n",
      "Current accuracy: 0.613\n",
      "Train loss: 1.0296905040740967\n",
      "Current accuracy: 0.658\n",
      "Current accuracy: 0.713\n",
      "Current accuracy: 0.708\n",
      "Current accuracy: 0.713\n",
      "Current accuracy: 0.702\n",
      "Train loss: 1.0799944400787354\n",
      "Current accuracy: 0.694\n",
      "Train loss: 1.1570526361465454\n",
      "Train loss: 1.0321842432022095\n",
      "Current accuracy: 0.745\n",
      "Current accuracy: 0.745\n",
      "Train loss: 1.1432452201843262\n",
      "Current accuracy: 0.78\n",
      "Reached accuracy: 0.78 in 4162 batches of size 64.\n",
      "Progress: 12 / 16\n",
      "Image width: 34\n",
      "Generating test data\n",
      "Number of hidden_neurons 258\n",
      "Generated FCNN with 298765 parameters\n",
      "Train loss: 1.020760416984558\n",
      "Train loss: 1.0380350351333618\n",
      "Train loss: 1.399521827697754\n",
      "Train loss: 1.036186933517456\n",
      "Train loss: 1.3585913181304932\n",
      "Train loss: 1.143913745880127\n",
      "Train loss: 1.0366822481155396\n",
      "Train loss: 1.007754921913147\n",
      "Train loss: 1.0495405197143555\n",
      "Train loss: 1.0755406618118286\n",
      "Train loss: 1.0140669345855713\n",
      "Train loss: 1.0317589044570923\n",
      "Train loss: 1.063493251800537\n",
      "Train loss: 1.0155422687530518\n",
      "Train loss: 1.0071581602096558\n",
      "Train loss: 1.0154719352722168\n",
      "Train loss: 1.004725456237793\n",
      "Train loss: 1.1008464097976685\n",
      "Train loss: 1.1230623722076416\n",
      "Train loss: 1.24578857421875\n",
      "Train loss: 1.0854601860046387\n",
      "Train loss: 1.0547690391540527\n",
      "Train loss: 1.0344278812408447\n",
      "Train loss: 1.0315535068511963\n",
      "Train loss: 1.0510872602462769\n",
      "Train loss: 1.1115453243255615\n",
      "Current accuracy: 0.582\n",
      "Current accuracy: 0.557\n",
      "Current accuracy: 0.654\n",
      "Train loss: 1.0009198188781738\n",
      "Train loss: 1.0383423566818237\n",
      "Current accuracy: 0.585\n",
      "Train loss: 1.232624888420105\n",
      "Current accuracy: 0.665\n",
      "Current accuracy: 0.677\n",
      "Current accuracy: 0.657\n",
      "Current accuracy: 0.689\n",
      "Current accuracy: 0.675\n",
      "Current accuracy: 0.606\n",
      "Train loss: 1.0069273710250854\n",
      "Train loss: 2.2283804416656494\n",
      "Train loss: 1.033452033996582\n",
      "Train loss: 1.096031665802002\n",
      "Current accuracy: 0.736\n",
      "Current accuracy: 0.589\n",
      "Train loss: 1.2141468524932861\n",
      "Current accuracy: 0.749\n",
      "Train loss: 1.0019845962524414\n",
      "Train loss: 1.1670866012573242\n",
      "Train loss: 1.044223666191101\n",
      "Train loss: 1.0460566282272339\n",
      "Train loss: 2.3020095825195312\n",
      "Train loss: 2.107346534729004\n",
      "Train loss: 2.2319350242614746\n",
      "Current accuracy: 0.766\n",
      "Reached accuracy: 0.766 in 4843 batches of size 64.\n",
      "Progress: 13 / 16\n",
      "Image width: 36\n",
      "Generating test data\n",
      "Number of hidden_neurons 257\n",
      "Generated FCNN with 333587 parameters\n",
      "Train loss: 1.0051801204681396\n",
      "Train loss: 1.164933204650879\n",
      "Train loss: 1.0013259649276733\n",
      "Train loss: 1.0415524244308472\n",
      "Train loss: 1.0831891298294067\n",
      "Current accuracy: 0.494\n",
      "Train loss: 1.07667875289917\n",
      "Train loss: 1.004120111465454\n",
      "Train loss: 1.0878522396087646\n",
      "Train loss: 1.167968511581421\n",
      "Train loss: 1.1491354703903198\n",
      "Train loss: 1.1708849668502808\n",
      "Train loss: 1.0420901775360107\n",
      "Train loss: 1.0379881858825684\n",
      "Train loss: 1.2011038064956665\n",
      "Train loss: 1.007865309715271\n",
      "Train loss: 1.1075459718704224\n",
      "Train loss: 1.0203279256820679\n",
      "Train loss: 1.0319510698318481\n",
      "Train loss: 1.0794209241867065\n",
      "Train loss: 1.154200553894043\n",
      "Train loss: 1.37843656539917\n",
      "Train loss: 1.1751424074172974\n",
      "Train loss: 1.0591846704483032\n",
      "Train loss: 1.0229840278625488\n",
      "Train loss: 1.0194242000579834\n",
      "Train loss: 1.0060502290725708\n",
      "Train loss: 1.0092066526412964\n",
      "Train loss: 1.123253345489502\n",
      "Train loss: 1.0110499858856201\n",
      "Train loss: 1.0060365200042725\n",
      "Train loss: 1.1467028856277466\n",
      "Train loss: 1.0135124921798706\n",
      "Train loss: 1.1800432205200195\n",
      "Train loss: 1.0446358919143677\n",
      "Current accuracy: 0.506\n",
      "Train loss: 1.0326621532440186\n",
      "Train loss: 1.1132224798202515\n",
      "Train loss: 1.0186467170715332\n",
      "Train loss: 1.1503585577011108\n",
      "Train loss: 1.043880820274353\n",
      "Train loss: 1.0073951482772827\n",
      "Train loss: 1.1469730138778687\n",
      "Train loss: 1.0284441709518433\n",
      "Train loss: 1.0368624925613403\n",
      "Train loss: 1.0031673908233643\n",
      "Train loss: 1.0646511316299438\n",
      "Train loss: 1.0442191362380981\n",
      "Train loss: 1.0526906251907349\n",
      "Train loss: 1.0184826850891113\n",
      "Train loss: 1.0230445861816406\n",
      "Train loss: 1.0344661474227905\n",
      "Train loss: 1.02251136302948\n",
      "Current accuracy: 0.529\n",
      "Current accuracy: 0.512\n",
      "Train loss: 1.5285673141479492\n",
      "Train loss: 1.5523303747177124\n",
      "Train loss: 1.1253626346588135\n",
      "Train loss: 1.131901502609253\n",
      "Train loss: 1.0476875305175781\n",
      "Train loss: 1.1909208297729492\n",
      "Train loss: 1.084666132926941\n",
      "Current accuracy: 0.601\n",
      "Train loss: 1.0639944076538086\n",
      "Train loss: 1.0392050743103027\n",
      "Current accuracy: 0.699\n",
      "Train loss: 1.0566352605819702\n",
      "Current accuracy: 0.706\n",
      "Train loss: 1.0232181549072266\n",
      "Train loss: 1.0412960052490234\n",
      "Current accuracy: 0.712\n",
      "Current accuracy: 0.675\n",
      "Train loss: 1.1362195014953613\n",
      "Train loss: 1.0846669673919678\n",
      "Train loss: 1.096056580543518\n",
      "Current accuracy: 0.743\n",
      "Train loss: 1.063985824584961\n",
      "Current accuracy: 0.738\n",
      "Train loss: 2.244966745376587\n",
      "Train loss: 1.0779926776885986\n",
      "Train loss: 2.193570613861084\n",
      "Train loss: 1.0065462589263916\n",
      "Current accuracy: 0.773\n",
      "Reached accuracy: 0.773 in 4502 batches of size 64.\n",
      "Progress: 14 / 16\n",
      "Image width: 38\n",
      "Generating test data\n",
      "Number of hidden_neurons 256\n",
      "Generated FCNN with 370177 parameters\n",
      "Train loss: 1.0238945484161377\n",
      "Train loss: 1.193534255027771\n",
      "Current accuracy: 0.484\n",
      "Train loss: 1.1409974098205566\n",
      "Train loss: 1.2217153310775757\n",
      "Train loss: 1.0532301664352417\n",
      "Train loss: 1.0104434490203857\n",
      "Train loss: 1.0642752647399902\n",
      "Train loss: 1.093371868133545\n",
      "Train loss: 1.0528290271759033\n",
      "Train loss: 1.0230927467346191\n",
      "Train loss: 1.018999695777893\n",
      "Train loss: 1.0507270097732544\n",
      "Train loss: 1.0583529472351074\n",
      "Train loss: 1.0911414623260498\n",
      "Train loss: 1.0371410846710205\n",
      "Train loss: 1.1278995275497437\n",
      "Train loss: 1.0051621198654175\n",
      "Train loss: 1.0707937479019165\n",
      "Train loss: 1.0315675735473633\n",
      "Train loss: 1.1295253038406372\n",
      "Train loss: 1.062853217124939\n",
      "Train loss: 1.0179650783538818\n",
      "Train loss: 1.2126185894012451\n",
      "Train loss: 1.0924677848815918\n",
      "Train loss: 1.1974921226501465\n",
      "Train loss: 1.1382101774215698\n",
      "Train loss: 1.0050556659698486\n",
      "Train loss: 1.4879817962646484\n",
      "Train loss: 1.1888134479522705\n",
      "Train loss: 1.0928653478622437\n",
      "Train loss: 1.1491612195968628\n",
      "Train loss: 1.0132960081100464\n",
      "Train loss: 1.075837254524231\n",
      "Train loss: 1.1186037063598633\n",
      "Train loss: 1.0650787353515625\n",
      "Train loss: 1.0083410739898682\n",
      "Train loss: 1.0797407627105713\n",
      "Train loss: 1.0018283128738403\n",
      "Train loss: 1.0278996229171753\n",
      "Train loss: 1.038603663444519\n",
      "Train loss: 1.1354126930236816\n",
      "Train loss: 1.0126816034317017\n",
      "Train loss: 1.0741987228393555\n",
      "Train loss: 1.1113595962524414\n",
      "Current accuracy: 0.517\n",
      "Train loss: 1.1294305324554443\n",
      "Train loss: 1.176566243171692\n",
      "Train loss: 1.0115689039230347\n",
      "Train loss: 1.1216051578521729\n",
      "Train loss: 1.1364902257919312\n",
      "Train loss: 1.0474107265472412\n",
      "Train loss: 1.2520859241485596\n",
      "Train loss: 1.0668147802352905\n",
      "Train loss: 1.1223933696746826\n",
      "Train loss: 1.005812644958496\n",
      "Train loss: 1.0636265277862549\n",
      "Train loss: 1.2120805978775024\n",
      "Train loss: 1.1386005878448486\n",
      "Train loss: 1.050311803817749\n",
      "Train loss: 1.122273325920105\n",
      "Train loss: 1.1002113819122314\n",
      "Train loss: 1.1298056840896606\n",
      "Train loss: 1.1897287368774414\n",
      "Train loss: 1.0367684364318848\n",
      "Train loss: 1.3131288290023804\n",
      "Train loss: 1.0748469829559326\n",
      "Train loss: 1.0024877786636353\n",
      "Train loss: 1.015833854675293\n",
      "Train loss: 1.0471751689910889\n",
      "Train loss: 1.0574555397033691\n",
      "Train loss: 1.1315335035324097\n",
      "Train loss: 1.0404860973358154\n",
      "Train loss: 1.010347604751587\n",
      "Train loss: 1.009831190109253\n",
      "Train loss: 1.0146313905715942\n",
      "Train loss: 1.1152241230010986\n",
      "Train loss: 1.0609745979309082\n",
      "Train loss: 1.2281160354614258\n",
      "Train loss: 1.1312975883483887\n",
      "Train loss: 1.097097635269165\n",
      "Train loss: 1.139920711517334\n",
      "Train loss: 1.0642585754394531\n",
      "Train loss: 1.0370607376098633\n",
      "Train loss: 1.0112638473510742\n",
      "Train loss: 1.0019192695617676\n",
      "Train loss: 1.1042022705078125\n",
      "Train loss: 1.1448249816894531\n",
      "Train loss: 1.2092204093933105\n",
      "Train loss: 1.0224558115005493\n",
      "Train loss: 1.0799899101257324\n",
      "Train loss: 1.002761721611023\n",
      "Train loss: 1.063201904296875\n",
      "Current accuracy: 0.611\n",
      "Current accuracy: 0.557\n",
      "Current accuracy: 0.565\n",
      "Train loss: 1.0116649866104126\n",
      "Train loss: 1.0337810516357422\n",
      "Train loss: 1.03627610206604\n",
      "Train loss: 1.0057644844055176\n",
      "Train loss: 1.0671756267547607\n",
      "Train loss: 1.0348206758499146\n",
      "Train loss: 1.2028547525405884\n",
      "Train loss: 1.0358970165252686\n",
      "Train loss: 1.0388394594192505\n",
      "Current accuracy: 0.664\n",
      "Current accuracy: 0.631\n",
      "Train loss: 1.0013821125030518\n",
      "Current accuracy: 0.609\n",
      "Train loss: 1.1695646047592163\n",
      "Current accuracy: 0.684\n",
      "Current accuracy: 0.698\n",
      "Current accuracy: 0.715\n",
      "Current accuracy: 0.613\n",
      "Train loss: 1.0037370920181274\n",
      "Current accuracy: 0.698\n",
      "Train loss: 1.0875495672225952\n",
      "Train loss: 1.1508060693740845\n",
      "Current accuracy: 0.72\n",
      "Train loss: 1.0170687437057495\n",
      "Train loss: 2.0938291549682617\n",
      "Train loss: 2.117551803588867\n",
      "Train loss: 2.1683623790740967\n",
      "Current accuracy: 0.622\n",
      "Train loss: 1.0716272592544556\n",
      "Train loss: 2.0512688159942627\n",
      "Train loss: 1.9806239604949951\n",
      "Train loss: 1.191605806350708\n",
      "Train loss: 2.3173255920410156\n",
      "Train loss: 1.9761298894882202\n",
      "Current accuracy: 0.768\n",
      "Reached accuracy: 0.768 in 6145 batches of size 64.\n",
      "Progress: 15 / 16\n",
      "Image width: 40\n",
      "Generating test data\n",
      "Number of hidden_neurons 256\n",
      "Generated FCNN with 410113 parameters\n",
      "Train loss: 1.079656958580017\n",
      "Train loss: 1.0264644622802734\n",
      "Current accuracy: 0.478\n",
      "Train loss: 1.3152978420257568\n",
      "Train loss: 1.1529117822647095\n",
      "Train loss: 1.0300226211547852\n",
      "Train loss: 1.0738393068313599\n",
      "Train loss: 1.047433853149414\n",
      "Train loss: 1.05869460105896\n",
      "Train loss: 1.2851969003677368\n",
      "Train loss: 1.0084781646728516\n",
      "Train loss: 1.019512414932251\n",
      "Train loss: 1.0350143909454346\n",
      "Train loss: 1.1523768901824951\n",
      "Train loss: 1.0106289386749268\n",
      "Train loss: 1.1700220108032227\n",
      "Train loss: 1.0371094942092896\n",
      "Train loss: 1.0173883438110352\n",
      "Train loss: 1.2322748899459839\n",
      "Train loss: 1.0693018436431885\n",
      "Train loss: 1.0747257471084595\n",
      "Train loss: 1.0671026706695557\n",
      "Train loss: 1.1174781322479248\n",
      "Train loss: 1.1137919425964355\n",
      "Train loss: 1.0628504753112793\n",
      "Train loss: 1.0262606143951416\n",
      "Train loss: 1.0288894176483154\n",
      "Train loss: 1.0495705604553223\n",
      "Train loss: 1.069836139678955\n",
      "Train loss: 1.0073866844177246\n",
      "Train loss: 1.065986156463623\n",
      "Train loss: 1.1176966428756714\n",
      "Train loss: 1.0492733716964722\n",
      "Train loss: 1.0698093175888062\n",
      "Train loss: 1.1148645877838135\n",
      "Train loss: 1.1462153196334839\n",
      "Train loss: 1.029862880706787\n",
      "Train loss: 1.1494927406311035\n",
      "Train loss: 1.0759031772613525\n",
      "Train loss: 1.0059258937835693\n",
      "Train loss: 1.0594990253448486\n",
      "Train loss: 1.0444337129592896\n",
      "Train loss: 1.0549871921539307\n",
      "Train loss: 1.0324939489364624\n",
      "Train loss: 1.550504446029663\n",
      "Train loss: 1.6948964595794678\n",
      "Train loss: 1.0461781024932861\n",
      "Train loss: 1.4707547426223755\n",
      "Train loss: 1.050168752670288\n",
      "Train loss: 1.1016547679901123\n",
      "Train loss: 1.194731593132019\n",
      "Train loss: 1.0913379192352295\n",
      "Train loss: 1.1756583452224731\n",
      "Train loss: 1.133682370185852\n",
      "Train loss: 1.0202691555023193\n",
      "Train loss: 1.3067494630813599\n",
      "Train loss: 1.3113845586776733\n",
      "Train loss: 1.2951817512512207\n",
      "Train loss: 1.3507856130599976\n",
      "Train loss: 1.0608673095703125\n",
      "Train loss: 1.0074071884155273\n",
      "Train loss: 1.1264818906784058\n",
      "Train loss: 1.1428967714309692\n",
      "Train loss: 1.047278642654419\n",
      "Train loss: 1.126319169998169\n",
      "Train loss: 1.074793815612793\n",
      "Train loss: 1.0330649614334106\n",
      "Train loss: 1.1558001041412354\n",
      "Train loss: 1.0399320125579834\n",
      "Train loss: 1.0576685667037964\n",
      "Train loss: 1.2886260747909546\n",
      "Train loss: 1.3587743043899536\n",
      "Train loss: 1.1006155014038086\n",
      "Train loss: 1.3540583848953247\n",
      "Train loss: 1.0996899604797363\n",
      "Train loss: 1.2002977132797241\n",
      "Train loss: 1.0983189344406128\n",
      "Train loss: 1.0631269216537476\n",
      "Train loss: 1.239794135093689\n",
      "Train loss: 1.6377575397491455\n",
      "Train loss: 1.1626853942871094\n",
      "Train loss: 1.036787986755371\n",
      "Train loss: 1.1589078903198242\n",
      "Train loss: 1.0694105625152588\n",
      "Train loss: 1.000929355621338\n",
      "Train loss: 1.0337157249450684\n",
      "Train loss: 1.0504937171936035\n",
      "Train loss: 1.0880497694015503\n",
      "Train loss: 1.0166486501693726\n",
      "Train loss: 1.025696039199829\n",
      "Train loss: 1.011106014251709\n",
      "Train loss: 1.0297714471817017\n",
      "Train loss: 1.0557132959365845\n",
      "Train loss: 1.0207716226577759\n",
      "Train loss: 1.038201093673706\n",
      "Train loss: 1.0517600774765015\n",
      "Train loss: 1.0110867023468018\n",
      "Train loss: 1.0097182989120483\n",
      "Train loss: 1.0624191761016846\n",
      "Train loss: 1.0010242462158203\n",
      "Train loss: 1.0677928924560547\n",
      "Train loss: 1.0027326345443726\n",
      "Train loss: 1.0972133874893188\n",
      "Train loss: 1.1698322296142578\n",
      "Train loss: 1.0436668395996094\n",
      "Train loss: 1.155516505241394\n",
      "Current accuracy: 0.481\n",
      "Train loss: 1.2751497030258179\n",
      "Train loss: 1.245639443397522\n",
      "Train loss: 1.056469440460205\n",
      "Train loss: 1.2893396615982056\n",
      "Train loss: 1.183531403541565\n",
      "Train loss: 1.0513062477111816\n",
      "Current accuracy: 0.484\n",
      "Train loss: 1.2966325283050537\n",
      "Train loss: 1.1251864433288574\n",
      "Train loss: 1.0486857891082764\n",
      "Train loss: 1.0055570602416992\n",
      "Train loss: 1.1469721794128418\n",
      "Train loss: 1.018112063407898\n",
      "Train loss: 1.0660861730575562\n",
      "Train loss: 1.0807981491088867\n",
      "Train loss: 1.006962537765503\n",
      "Train loss: 1.353757619857788\n",
      "Train loss: 1.080976128578186\n",
      "Train loss: 1.2960569858551025\n",
      "Train loss: 1.009007453918457\n",
      "Train loss: 1.0279704332351685\n",
      "Train loss: 1.0616475343704224\n",
      "Train loss: 1.0056068897247314\n",
      "Train loss: 1.0480594635009766\n",
      "Train loss: 1.0528345108032227\n",
      "Train loss: 1.006622314453125\n",
      "Train loss: 1.034706950187683\n",
      "Current accuracy: 0.556\n",
      "Train loss: 1.0060657262802124\n",
      "Current accuracy: 0.547\n",
      "Train loss: 1.0645146369934082\n",
      "Train loss: 1.0004279613494873\n",
      "Train loss: 1.0463987588882446\n",
      "Train loss: 1.0172185897827148\n",
      "Train loss: 1.0992827415466309\n",
      "Train loss: 1.0018433332443237\n",
      "Train loss: 1.1171354055404663\n",
      "Train loss: 1.1330139636993408\n",
      "Current accuracy: 0.589\n",
      "Train loss: 1.041991949081421\n",
      "Train loss: 1.0668916702270508\n",
      "Train loss: 1.0872794389724731\n",
      "Train loss: 1.0276631116867065\n",
      "Train loss: 1.0303465127944946\n",
      "Train loss: 1.0281364917755127\n",
      "Current accuracy: 0.606\n",
      "Current accuracy: 0.565\n",
      "Current accuracy: 0.542\n",
      "Train loss: 1.37448251247406\n",
      "Train loss: 1.1001241207122803\n",
      "Train loss: 1.3424867391586304\n",
      "Train loss: 1.017393946647644\n",
      "Train loss: 1.0325655937194824\n",
      "Train loss: 1.0616052150726318\n",
      "Train loss: 1.0327340364456177\n",
      "Train loss: 1.0292587280273438\n",
      "Train loss: 1.0060631036758423\n",
      "Train loss: 1.0865533351898193\n",
      "Train loss: 1.0210423469543457\n",
      "Train loss: 1.031805396080017\n",
      "Train loss: 1.0154346227645874\n",
      "Train loss: 1.0988582372665405\n",
      "Train loss: 1.0104913711547852\n",
      "Train loss: 1.0550761222839355\n",
      "Train loss: 1.202643632888794\n",
      "Train loss: 1.187955379486084\n",
      "Train loss: 1.0197241306304932\n",
      "Train loss: 1.139962911605835\n",
      "Train loss: 1.0780779123306274\n",
      "Train loss: 1.1876842975616455\n",
      "Train loss: 1.0085029602050781\n",
      "Train loss: 1.147581934928894\n",
      "Train loss: 1.0555534362792969\n",
      "Current accuracy: 0.654\n",
      "Current accuracy: 0.674\n",
      "Current accuracy: 0.658\n",
      "Train loss: 1.0124074220657349\n",
      "Train loss: 1.0177935361862183\n",
      "Train loss: 1.0325348377227783\n",
      "Train loss: 1.1762362718582153\n",
      "Train loss: 1.1638824939727783\n",
      "Train loss: 2.407221555709839\n",
      "Current accuracy: 0.646\n",
      "Train loss: 1.0112628936767578\n",
      "Train loss: 2.0233097076416016\n",
      "Train loss: 1.1545791625976562\n",
      "Train loss: 2.0884058475494385\n",
      "Train loss: 1.0153892040252686\n",
      "Current accuracy: 0.715\n",
      "Current accuracy: 0.718\n",
      "Train loss: 1.9687787294387817\n",
      "Current accuracy: 0.751\n",
      "Reached accuracy: 0.751 in 6502 batches of size 64.\n",
      "Progress: 16 / 16\n",
      "Image width: 10\n",
      "Generating test data\n",
      "Number of hidden_neurons 346\n",
      "Generated FCNN with 35293 parameters\n",
      "Current accuracy: 0.68\n",
      "Current accuracy: 0.68\n",
      "Current accuracy: 0.74\n",
      "Current accuracy: 0.758\n",
      "Reached accuracy: 0.758 in 281 batches of size 64.\n",
      "Progress: 1 / 16\n",
      "Image width: 12\n",
      "Generating test data\n",
      "Number of hidden_neurons 317\n",
      "Generated FCNN with 46283 parameters\n",
      "Current accuracy: 0.716\n",
      "Current accuracy: 0.746\n",
      "Current accuracy: 0.739\n",
      "Current accuracy: 0.753\n",
      "Reached accuracy: 0.753 in 345 batches of size 64.\n",
      "Progress: 2 / 16\n",
      "Image width: 14\n",
      "Generating test data\n",
      "Number of hidden_neurons 299\n",
      "Generated FCNN with 59203 parameters\n",
      "Current accuracy: 0.676\n",
      "Current accuracy: 0.681\n",
      "Current accuracy: 0.704\n",
      "Current accuracy: 0.738\n",
      "Current accuracy: 0.734\n",
      "Current accuracy: 0.708\n",
      "Current accuracy: 0.786\n",
      "Reached accuracy: 0.786 in 586 batches of size 64.\n",
      "Progress: 3 / 16\n",
      "Image width: 16\n",
      "Generating test data\n",
      "Number of hidden_neurons 287\n",
      "Generated FCNN with 74047 parameters\n",
      "Current accuracy: 0.607\n",
      "Current accuracy: 0.627\n",
      "Current accuracy: 0.652\n",
      "Current accuracy: 0.696\n",
      "Current accuracy: 0.718\n",
      "Current accuracy: 0.755\n",
      "Reached accuracy: 0.755 in 715 batches of size 64.\n",
      "Progress: 4 / 16\n",
      "Image width: 18\n",
      "Generating test data\n",
      "Number of hidden_neurons 280\n",
      "Generated FCNN with 91281 parameters\n",
      "Current accuracy: 0.602\n",
      "Current accuracy: 0.657\n",
      "Current accuracy: 0.663\n",
      "Current accuracy: 0.68\n",
      "Current accuracy: 0.716\n",
      "Current accuracy: 0.712\n",
      "Current accuracy: 0.742\n",
      "Current accuracy: 0.758\n",
      "Reached accuracy: 0.758 in 899 batches of size 64.\n",
      "Progress: 5 / 16\n",
      "Image width: 20\n",
      "Generating test data\n",
      "Number of hidden_neurons 274\n",
      "Generated FCNN with 110149 parameters\n",
      "Current accuracy: 0.507\n",
      "Current accuracy: 0.604\n",
      "Current accuracy: 0.655\n",
      "Current accuracy: 0.661\n",
      "Current accuracy: 0.588\n",
      "Current accuracy: 0.729\n",
      "Current accuracy: 0.714\n",
      "Current accuracy: 0.727\n",
      "Current accuracy: 0.745\n",
      "Current accuracy: 0.76\n",
      "Reached accuracy: 0.76 in 1134 batches of size 64.\n",
      "Progress: 6 / 16\n",
      "Image width: 22\n",
      "Generating test data\n",
      "Number of hidden_neurons 270\n",
      "Generated FCNN with 131221 parameters\n",
      "Current accuracy: 0.575\n",
      "Current accuracy: 0.639\n",
      "Current accuracy: 0.618\n",
      "Current accuracy: 0.712\n",
      "Current accuracy: 0.718\n",
      "Current accuracy: 0.717\n",
      "Current accuracy: 0.712\n",
      "Current accuracy: 0.751\n",
      "Reached accuracy: 0.751 in 1357 batches of size 64.\n",
      "Progress: 7 / 16\n",
      "Image width: 24\n",
      "Generating test data\n",
      "Number of hidden_neurons 266\n",
      "Generated FCNN with 153749 parameters\n",
      "Train loss: 1.009230136871338\n",
      "Current accuracy: 0.575\n",
      "Current accuracy: 0.628\n",
      "Current accuracy: 0.63\n",
      "Train loss: 1.016281008720398\n",
      "Current accuracy: 0.589\n",
      "Train loss: 1.0195423364639282\n",
      "Train loss: 1.047852873802185\n",
      "Current accuracy: 0.708\n",
      "Current accuracy: 0.706\n",
      "Current accuracy: 0.706\n",
      "Current accuracy: 0.749\n",
      "Current accuracy: 0.745\n",
      "Current accuracy: 0.76\n",
      "Reached accuracy: 0.76 in 1722 batches of size 64.\n",
      "Progress: 8 / 16\n",
      "Image width: 26\n",
      "Generating test data\n",
      "Number of hidden_neurons 264\n",
      "Generated FCNN with 178993 parameters\n",
      "Train loss: 1.0070993900299072\n",
      "Current accuracy: 0.532\n",
      "Current accuracy: 0.568\n",
      "Current accuracy: 0.58\n",
      "Current accuracy: 0.662\n",
      "Current accuracy: 0.706\n",
      "Current accuracy: 0.699\n",
      "Current accuracy: 0.7\n",
      "Current accuracy: 0.694\n",
      "Current accuracy: 0.729\n",
      "Current accuracy: 0.735\n",
      "Train loss: 1.0414302349090576\n",
      "Current accuracy: 0.727\n",
      "Train loss: 2.036520004272461\n",
      "Train loss: 1.059897780418396\n",
      "Current accuracy: 0.748\n",
      "Current accuracy: 0.767\n",
      "Reached accuracy: 0.767 in 2416 batches of size 64.\n",
      "Progress: 9 / 16\n",
      "Image width: 28\n",
      "Generating test data\n",
      "Number of hidden_neurons 262\n",
      "Generated FCNN with 205933 parameters\n",
      "Train loss: 1.0296258926391602\n",
      "Train loss: 1.0808897018432617\n",
      "Train loss: 1.0642122030258179\n",
      "Train loss: 1.0022462606430054\n",
      "Train loss: 1.0179038047790527\n",
      "Current accuracy: 0.601\n",
      "Current accuracy: 0.585\n",
      "Current accuracy: 0.562\n",
      "Train loss: 1.0078321695327759\n",
      "Current accuracy: 0.609\n",
      "Current accuracy: 0.628\n",
      "Current accuracy: 0.65\n",
      "Current accuracy: 0.658\n",
      "Current accuracy: 0.576\n",
      "Train loss: 1.105159044265747\n",
      "Train loss: 2.4980740547180176\n",
      "Current accuracy: 0.705\n",
      "Current accuracy: 0.752\n",
      "Reached accuracy: 0.752 in 2508 batches of size 64.\n",
      "Progress: 10 / 16\n",
      "Image width: 30\n",
      "Generating test data\n",
      "Number of hidden_neurons 260\n",
      "Generated FCNN with 234521 parameters\n",
      "Train loss: 1.0107600688934326\n",
      "Train loss: 1.0146675109863281\n",
      "Train loss: 1.0041159391403198\n",
      "Train loss: 1.0258586406707764\n",
      "Train loss: 1.0712993144989014\n",
      "Current accuracy: 0.503\n",
      "Train loss: 1.0128042697906494\n",
      "Train loss: 1.044862985610962\n",
      "Train loss: 1.2405120134353638\n",
      "Train loss: 1.122814416885376\n",
      "Current accuracy: 0.503\n",
      "Train loss: 1.0181963443756104\n",
      "Current accuracy: 0.567\n",
      "Train loss: 1.0721057653427124\n",
      "Train loss: 1.0670570135116577\n",
      "Current accuracy: 0.672\n",
      "Current accuracy: 0.71\n",
      "Current accuracy: 0.73\n",
      "Current accuracy: 0.741\n",
      "Current accuracy: 0.708\n",
      "Current accuracy: 0.71\n",
      "Current accuracy: 0.712\n",
      "Train loss: 1.069003701210022\n",
      "Current accuracy: 0.774\n",
      "Reached accuracy: 0.774 in 2788 batches of size 64.\n",
      "Progress: 11 / 16\n",
      "Image width: 32\n",
      "Generating test data\n",
      "Number of hidden_neurons 259\n",
      "Generated FCNN with 265735 parameters\n",
      "Train loss: 1.022188663482666\n",
      "Train loss: 1.0078624486923218\n",
      "Train loss: 1.0081290006637573\n",
      "Train loss: 1.01381254196167\n",
      "Train loss: 1.0395094156265259\n",
      "Train loss: 1.0490479469299316\n",
      "Train loss: 1.1097376346588135\n",
      "Train loss: 1.0362929105758667\n",
      "Train loss: 1.1536587476730347\n",
      "Train loss: 1.0063470602035522\n",
      "Train loss: 1.1403326988220215\n",
      "Train loss: 1.008487582206726\n",
      "Train loss: 1.1285083293914795\n",
      "Train loss: 1.025145411491394\n",
      "Train loss: 1.0091304779052734\n",
      "Current accuracy: 0.599\n",
      "Current accuracy: 0.558\n",
      "Train loss: 1.0550378561019897\n",
      "Train loss: 1.0379480123519897\n",
      "Current accuracy: 0.628\n",
      "Train loss: 1.0125248432159424\n",
      "Train loss: 1.0740653276443481\n",
      "Current accuracy: 0.643\n",
      "Current accuracy: 0.58\n",
      "Train loss: 1.1134371757507324\n",
      "Train loss: 1.0812853574752808\n",
      "Current accuracy: 0.689\n",
      "Current accuracy: 0.687\n",
      "Current accuracy: 0.677\n",
      "Current accuracy: 0.618\n",
      "Current accuracy: 0.699\n",
      "Current accuracy: 0.721\n",
      "Train loss: 1.0120383501052856\n",
      "Current accuracy: 0.73\n",
      "Train loss: 2.129117488861084\n",
      "Current accuracy: 0.758\n",
      "Reached accuracy: 0.758 in 3459 batches of size 64.\n",
      "Progress: 12 / 16\n",
      "Image width: 34\n",
      "Generating test data\n",
      "Number of hidden_neurons 258\n",
      "Generated FCNN with 298765 parameters\n",
      "Train loss: 1.078936219215393\n",
      "Current accuracy: 0.489\n",
      "Train loss: 1.0338053703308105\n",
      "Train loss: 1.0212223529815674\n",
      "Train loss: 1.109326958656311\n",
      "Train loss: 1.0026847124099731\n",
      "Train loss: 1.028165340423584\n",
      "Train loss: 1.0701818466186523\n",
      "Train loss: 1.1213093996047974\n",
      "Train loss: 1.009185552597046\n",
      "Train loss: 1.082139015197754\n",
      "Train loss: 1.0022287368774414\n",
      "Train loss: 1.002874732017517\n",
      "Train loss: 1.014223337173462\n",
      "Train loss: 1.0541974306106567\n",
      "Train loss: 1.0194426774978638\n",
      "Train loss: 1.016634225845337\n",
      "Train loss: 1.0735244750976562\n",
      "Train loss: 1.0039887428283691\n",
      "Train loss: 1.0252364873886108\n",
      "Current accuracy: 0.488\n",
      "Train loss: 1.3229424953460693\n",
      "Train loss: 1.1876943111419678\n",
      "Train loss: 1.2026962041854858\n",
      "Train loss: 1.1151354312896729\n",
      "Train loss: 1.0653048753738403\n",
      "Train loss: 1.0614596605300903\n",
      "Train loss: 1.1732292175292969\n",
      "Train loss: 1.1250901222229004\n",
      "Train loss: 1.0170186758041382\n",
      "Train loss: 1.0315439701080322\n",
      "Train loss: 1.1519476175308228\n",
      "Current accuracy: 0.576\n",
      "Train loss: 1.0610450506210327\n",
      "Current accuracy: 0.534\n",
      "Train loss: 1.1003854274749756\n",
      "Train loss: 1.0821278095245361\n",
      "Current accuracy: 0.628\n",
      "Train loss: 1.184208631515503\n",
      "Train loss: 1.0040199756622314\n",
      "Current accuracy: 0.663\n",
      "Train loss: 1.2456889152526855\n",
      "Current accuracy: 0.652\n",
      "Train loss: 2.025529384613037\n",
      "Train loss: 1.045937180519104\n",
      "Train loss: 1.055206060409546\n",
      "Train loss: 2.0339267253875732\n",
      "Current accuracy: 0.685\n",
      "Current accuracy: 0.691\n",
      "Current accuracy: 0.743\n",
      "Train loss: 2.0187413692474365\n",
      "Current accuracy: 0.721\n",
      "Current accuracy: 0.702\n",
      "Train loss: 1.9152588844299316\n",
      "Current accuracy: 0.749\n",
      "Train loss: 2.0445573329925537\n",
      "Train loss: 1.0717289447784424\n",
      "Train loss: 1.0295623540878296\n",
      "Current accuracy: 0.774\n",
      "Reached accuracy: 0.774 in 4764 batches of size 64.\n",
      "Progress: 13 / 16\n",
      "Image width: 36\n",
      "Generating test data\n",
      "Number of hidden_neurons 257\n",
      "Generated FCNN with 333587 parameters\n",
      "Train loss: 1.0182198286056519\n",
      "Train loss: 1.0650893449783325\n",
      "Train loss: 1.0814729928970337\n",
      "Train loss: 1.1821608543395996\n",
      "Train loss: 1.019586205482483\n",
      "Train loss: 1.0140444040298462\n",
      "Train loss: 1.1007031202316284\n",
      "Train loss: 1.043699026107788\n",
      "Train loss: 1.1744505167007446\n",
      "Train loss: 1.1932096481323242\n",
      "Train loss: 1.0729453563690186\n",
      "Train loss: 1.015590786933899\n",
      "Train loss: 1.1237289905548096\n",
      "Train loss: 1.2674593925476074\n",
      "Current accuracy: 0.517\n",
      "Train loss: 1.1834754943847656\n",
      "Train loss: 1.3038891553878784\n",
      "Train loss: 1.28818678855896\n",
      "Train loss: 1.2756465673446655\n",
      "Train loss: 1.0650161504745483\n",
      "Train loss: 1.0725617408752441\n",
      "Train loss: 1.0733251571655273\n",
      "Train loss: 1.072762131690979\n",
      "Train loss: 1.2581584453582764\n",
      "Train loss: 1.0316970348358154\n",
      "Train loss: 1.0860633850097656\n",
      "Train loss: 1.0950491428375244\n",
      "Current accuracy: 0.525\n",
      "Train loss: 1.071043610572815\n",
      "Train loss: 1.065190315246582\n",
      "Train loss: 1.0255262851715088\n",
      "Train loss: 1.022308349609375\n",
      "Train loss: 1.023527979850769\n",
      "Train loss: 1.0299092531204224\n",
      "Train loss: 1.0336343050003052\n",
      "Train loss: 1.1424421072006226\n",
      "Train loss: 1.1770938634872437\n",
      "Train loss: 1.0159339904785156\n",
      "Train loss: 1.019655704498291\n",
      "Train loss: 1.029188632965088\n",
      "Train loss: 1.0578690767288208\n",
      "Train loss: 1.0378532409667969\n",
      "Current accuracy: 0.57\n",
      "Current accuracy: 0.637\n",
      "Current accuracy: 0.602\n",
      "Train loss: 1.0038368701934814\n",
      "Train loss: 1.0064126253128052\n",
      "Current accuracy: 0.563\n",
      "Train loss: 1.150759220123291\n",
      "Current accuracy: 0.596\n",
      "Train loss: 1.124979853630066\n",
      "Current accuracy: 0.634\n",
      "Train loss: 1.0139282941818237\n",
      "Train loss: 1.0096112489700317\n",
      "Current accuracy: 0.69\n",
      "Train loss: 1.9176065921783447\n",
      "Train loss: 1.0087976455688477\n",
      "Train loss: 2.111388921737671\n",
      "Current accuracy: 0.667\n",
      "Train loss: 1.0914347171783447\n",
      "Train loss: 2.230374336242676\n",
      "Current accuracy: 0.601\n",
      "Train loss: 1.143205165863037\n",
      "Train loss: 1.0338190793991089\n",
      "Train loss: 1.0180370807647705\n",
      "Current accuracy: 0.701\n",
      "Train loss: 2.396977663040161\n",
      "Train loss: 2.1554949283599854\n",
      "Train loss: 2.3345274925231934\n",
      "Train loss: 2.1216135025024414\n",
      "Current accuracy: 0.698\n",
      "Train loss: 1.992594599723816\n",
      "Train loss: 1.175337314605713\n",
      "Train loss: 1.045907735824585\n",
      "Train loss: 2.0703086853027344\n",
      "Train loss: 1.0758968591690063\n",
      "Current accuracy: 0.741\n",
      "Train loss: 2.1612367630004883\n",
      "Current accuracy: 0.757\n",
      "Reached accuracy: 0.757 in 4924 batches of size 64.\n",
      "Progress: 14 / 16\n",
      "Image width: 38\n",
      "Generating test data\n",
      "Number of hidden_neurons 256\n",
      "Generated FCNN with 370177 parameters\n",
      "Train loss: 1.0409555435180664\n",
      "Train loss: 1.0528068542480469\n",
      "Train loss: 1.1758701801300049\n",
      "Train loss: 1.0102343559265137\n",
      "Train loss: 1.032726764678955\n",
      "Train loss: 1.0178495645523071\n",
      "Train loss: 1.0039268732070923\n",
      "Train loss: 1.006698727607727\n",
      "Train loss: 1.0648703575134277\n",
      "Train loss: 1.080399990081787\n",
      "Train loss: 1.0795422792434692\n",
      "Train loss: 1.1122539043426514\n",
      "Train loss: 1.1474581956863403\n",
      "Train loss: 1.0720484256744385\n",
      "Train loss: 1.1036174297332764\n",
      "Train loss: 1.0359597206115723\n",
      "Train loss: 1.0441665649414062\n",
      "Train loss: 1.0068069696426392\n",
      "Train loss: 1.1984673738479614\n",
      "Train loss: 1.051835536956787\n",
      "Train loss: 1.2015459537506104\n",
      "Train loss: 1.3676879405975342\n",
      "Train loss: 1.1236841678619385\n",
      "Train loss: 1.0186737775802612\n",
      "Train loss: 1.0320768356323242\n",
      "Train loss: 1.0210351943969727\n",
      "Train loss: 1.3475135564804077\n",
      "Train loss: 1.0765043497085571\n",
      "Train loss: 1.0041065216064453\n",
      "Train loss: 1.002878189086914\n",
      "Train loss: 1.0190712213516235\n",
      "Train loss: 1.055263638496399\n",
      "Train loss: 1.0008430480957031\n",
      "Train loss: 1.0009962320327759\n",
      "Train loss: 1.009920358657837\n",
      "Train loss: 1.0146211385726929\n",
      "Train loss: 1.069340467453003\n",
      "Train loss: 1.0298740863800049\n",
      "Train loss: 1.0987865924835205\n",
      "Train loss: 1.0338523387908936\n",
      "Train loss: 1.0011144876480103\n",
      "Train loss: 1.14345383644104\n",
      "Train loss: 1.0509389638900757\n",
      "Current accuracy: 0.486\n",
      "Train loss: 1.3784747123718262\n",
      "Train loss: 1.0937892198562622\n",
      "Train loss: 1.124008059501648\n",
      "Train loss: 1.0156866312026978\n",
      "Train loss: 1.0014657974243164\n",
      "Train loss: 1.0806959867477417\n",
      "Train loss: 1.0852560997009277\n",
      "Train loss: 1.0822770595550537\n",
      "Train loss: 1.000162959098816\n",
      "Current accuracy: 0.537\n",
      "Current accuracy: 0.572\n",
      "Train loss: 1.093061923980713\n",
      "Train loss: 1.0096707344055176\n",
      "Current accuracy: 0.56\n",
      "Train loss: 1.0484068393707275\n",
      "Train loss: 1.0092898607254028\n",
      "Current accuracy: 0.531\n",
      "Train loss: 1.1491230726242065\n",
      "Train loss: 1.057086706161499\n",
      "Current accuracy: 0.653\n",
      "Train loss: 1.14335298538208\n",
      "Train loss: 1.106527328491211\n",
      "Train loss: 1.2160990238189697\n",
      "Train loss: 1.2217401266098022\n",
      "Train loss: 1.0173665285110474\n",
      "Current accuracy: 0.568\n",
      "Train loss: 1.0667104721069336\n",
      "Train loss: 1.0223915576934814\n",
      "Train loss: 1.0408849716186523\n",
      "Current accuracy: 0.647\n",
      "Current accuracy: 0.651\n",
      "Current accuracy: 0.583\n",
      "Train loss: 1.2445733547210693\n",
      "Train loss: 2.0263659954071045\n",
      "Current accuracy: 0.699\n",
      "Current accuracy: 0.569\n",
      "Train loss: 1.0516180992126465\n",
      "Train loss: 1.1713799238204956\n",
      "Train loss: 1.1008678674697876\n",
      "Train loss: 1.0154774188995361\n",
      "Train loss: 1.062375783920288\n",
      "Train loss: 3.7010066509246826\n",
      "Train loss: 1.0208661556243896\n",
      "Train loss: 2.1138203144073486\n",
      "Train loss: 2.0866081714630127\n",
      "Train loss: 2.0371618270874023\n",
      "Train loss: 2.1031131744384766\n",
      "Current accuracy: 0.732\n",
      "Train loss: 1.0118541717529297\n",
      "Train loss: 1.0883022546768188\n",
      "Train loss: 1.0136001110076904\n",
      "Current accuracy: 0.778\n",
      "Reached accuracy: 0.778 in 5997 batches of size 64.\n",
      "Progress: 15 / 16\n",
      "Image width: 40\n",
      "Generating test data\n",
      "Number of hidden_neurons 256\n",
      "Generated FCNN with 410113 parameters\n",
      "Train loss: 1.079489827156067\n",
      "Train loss: 1.0188405513763428\n",
      "Train loss: 1.0898170471191406\n",
      "Train loss: 1.0151848793029785\n",
      "Train loss: 1.0141304731369019\n",
      "Train loss: 1.0203243494033813\n",
      "Train loss: 1.0222975015640259\n",
      "Train loss: 1.1937353610992432\n",
      "Train loss: 1.1410106420516968\n",
      "Train loss: 1.0158771276474\n",
      "Train loss: 1.0402370691299438\n",
      "Train loss: 1.1228835582733154\n",
      "Train loss: 1.014840006828308\n",
      "Train loss: 1.020732045173645\n",
      "Train loss: 1.0804338455200195\n",
      "Train loss: 1.0695314407348633\n",
      "Train loss: 1.1320374011993408\n",
      "Train loss: 1.254730463027954\n",
      "Train loss: 1.666748046875\n",
      "Train loss: 1.0772674083709717\n",
      "Train loss: 1.1563550233840942\n",
      "Train loss: 1.197906732559204\n",
      "Train loss: 1.2298979759216309\n",
      "Train loss: 1.265940546989441\n",
      "Train loss: 1.2337843179702759\n",
      "Train loss: 1.1760835647583008\n",
      "Train loss: 1.0969966650009155\n",
      "Train loss: 1.0562083721160889\n",
      "Train loss: 1.0295132398605347\n",
      "Train loss: 1.1087708473205566\n",
      "Train loss: 1.0000171661376953\n",
      "Train loss: 1.0287774801254272\n",
      "Train loss: 1.0417981147766113\n",
      "Train loss: 1.033092737197876\n",
      "Train loss: 1.0000464916229248\n",
      "Train loss: 1.0436413288116455\n",
      "Train loss: 1.010026454925537\n",
      "Train loss: 1.0046969652175903\n",
      "Train loss: 1.0180556774139404\n",
      "Train loss: 1.0458626747131348\n",
      "Train loss: 1.0263633728027344\n",
      "Train loss: 1.096466302871704\n",
      "Train loss: 1.0413614511489868\n",
      "Train loss: 1.37104332447052\n",
      "Train loss: 1.000004529953003\n",
      "Train loss: 1.0080288648605347\n",
      "Train loss: 1.0640897750854492\n",
      "Train loss: 1.0434815883636475\n",
      "Train loss: 1.0501513481140137\n",
      "Train loss: 1.0477193593978882\n",
      "Train loss: 1.0077531337738037\n",
      "Train loss: 1.0056097507476807\n",
      "Train loss: 1.138554334640503\n",
      "Train loss: 1.1795523166656494\n",
      "Train loss: 1.0805517435073853\n",
      "Train loss: 1.1467368602752686\n",
      "Train loss: 1.0662176609039307\n",
      "Train loss: 1.149383544921875\n",
      "Train loss: 1.0466500520706177\n",
      "Train loss: 1.048448085784912\n",
      "Train loss: 1.0894795656204224\n",
      "Train loss: 1.1334240436553955\n",
      "Train loss: 1.0959303379058838\n",
      "Train loss: 1.0743635892868042\n",
      "Train loss: 1.004502773284912\n",
      "Train loss: 1.058552861213684\n",
      "Train loss: 1.0129790306091309\n",
      "Train loss: 1.0223512649536133\n",
      "Train loss: 1.2882689237594604\n",
      "Train loss: 1.1380937099456787\n",
      "Train loss: 1.4021306037902832\n",
      "Train loss: 1.0418169498443604\n",
      "Train loss: 1.1925424337387085\n",
      "Train loss: 1.2374366521835327\n",
      "Train loss: 1.0183191299438477\n",
      "Train loss: 1.2403452396392822\n",
      "Train loss: 1.1204502582550049\n",
      "Train loss: 1.0162855386734009\n",
      "Train loss: 1.0164542198181152\n",
      "Train loss: 1.0983153581619263\n",
      "Train loss: 1.0399813652038574\n",
      "Train loss: 1.0222548246383667\n",
      "Train loss: 1.0718038082122803\n",
      "Train loss: 1.1026743650436401\n",
      "Train loss: 1.0122870206832886\n",
      "Train loss: 1.063278317451477\n",
      "Train loss: 1.061444640159607\n",
      "Train loss: 1.0142443180084229\n",
      "Current accuracy: 0.534\n",
      "Train loss: 1.055965542793274\n",
      "Train loss: 1.012399435043335\n",
      "Train loss: 1.1295415163040161\n",
      "Train loss: 1.021586537361145\n",
      "Train loss: 1.0084538459777832\n",
      "Train loss: 1.0818400382995605\n",
      "Train loss: 1.087813377380371\n",
      "Train loss: 1.011473298072815\n",
      "Train loss: 1.0205868482589722\n",
      "Train loss: 1.1800706386566162\n",
      "Current accuracy: 0.567\n",
      "Train loss: 1.0246386528015137\n",
      "Train loss: 1.0915876626968384\n",
      "Train loss: 1.0666451454162598\n",
      "Train loss: 1.1247841119766235\n",
      "Train loss: 1.003103256225586\n",
      "Train loss: 1.1396818161010742\n",
      "Train loss: 1.0040483474731445\n",
      "Train loss: 1.105987310409546\n",
      "Train loss: 1.014630675315857\n",
      "Current accuracy: 0.536\n",
      "Train loss: 1.0277960300445557\n",
      "Train loss: 1.0335428714752197\n",
      "Train loss: 1.1892926692962646\n",
      "Train loss: 1.0406900644302368\n",
      "Current accuracy: 0.564\n",
      "Train loss: 1.098089575767517\n",
      "Train loss: 1.0431445837020874\n",
      "Train loss: 1.005096673965454\n",
      "Train loss: 1.0568976402282715\n",
      "Train loss: 1.0715601444244385\n",
      "Train loss: 1.14283287525177\n",
      "Train loss: 1.097517967224121\n",
      "Current accuracy: 0.568\n",
      "Train loss: 1.0469276905059814\n",
      "Train loss: 1.0090296268463135\n",
      "Train loss: 1.1451659202575684\n",
      "Train loss: 1.0207529067993164\n",
      "Train loss: 1.0466339588165283\n",
      "Train loss: 1.111856460571289\n",
      "Train loss: 1.0051511526107788\n",
      "Train loss: 1.0449252128601074\n",
      "Train loss: 1.0850484371185303\n",
      "Train loss: 1.1886775493621826\n",
      "Train loss: 1.0398162603378296\n",
      "Train loss: 1.0648648738861084\n",
      "Current accuracy: 0.646\n",
      "Current accuracy: 0.647\n",
      "Train loss: 1.0737524032592773\n",
      "Train loss: 1.039791226387024\n",
      "Train loss: 1.0724669694900513\n",
      "Train loss: 1.0550625324249268\n",
      "Train loss: 1.1967674493789673\n",
      "Train loss: 1.025594711303711\n",
      "Train loss: 1.0766944885253906\n",
      "Current accuracy: 0.585\n",
      "Train loss: 1.0538544654846191\n",
      "Train loss: 1.005324363708496\n",
      "Train loss: 1.0211726427078247\n",
      "Train loss: 1.0239506959915161\n",
      "Train loss: 1.0109502077102661\n",
      "Current accuracy: 0.666\n",
      "Train loss: 1.0713624954223633\n",
      "Train loss: 1.0459229946136475\n",
      "Current accuracy: 0.691\n",
      "Current accuracy: 0.659\n",
      "Train loss: 1.1096062660217285\n",
      "Current accuracy: 0.611\n",
      "Train loss: 1.2477387189865112\n",
      "Train loss: 1.1252007484436035\n",
      "Train loss: 1.0967462062835693\n",
      "Train loss: 1.0260090827941895\n",
      "Train loss: 1.038329839706421\n",
      "Current accuracy: 0.719\n",
      "Train loss: 1.0156217813491821\n",
      "Train loss: 1.0274642705917358\n",
      "Train loss: 1.0174976587295532\n",
      "Train loss: 1.0039396286010742\n",
      "Train loss: 1.00916588306427\n",
      "Train loss: 1.024788737297058\n",
      "Train loss: 2.3158133029937744\n",
      "Current accuracy: 0.739\n",
      "Train loss: 2.346346616744995\n",
      "Train loss: 2.047400951385498\n",
      "Train loss: 1.0001999139785767\n",
      "Train loss: 1.1687928438186646\n",
      "Train loss: 1.0484269857406616\n",
      "Train loss: 2.391862392425537\n",
      "Current accuracy: 0.775\n",
      "Reached accuracy: 0.775 in 6597 batches of size 64.\n",
      "Progress: 16 / 16\n",
      "Image width: 10\n",
      "Generating test data\n",
      "Number of hidden_neurons 346\n",
      "Generated FCNN with 35293 parameters\n",
      "Current accuracy: 0.71\n",
      "Current accuracy: 0.728\n",
      "Current accuracy: 0.74\n",
      "Current accuracy: 0.705\n",
      "Current accuracy: 0.759\n",
      "Reached accuracy: 0.759 in 322 batches of size 64.\n",
      "Progress: 1 / 16\n",
      "Image width: 12\n",
      "Generating test data\n",
      "Number of hidden_neurons 317\n",
      "Generated FCNN with 46283 parameters\n",
      "Current accuracy: 0.65\n",
      "Current accuracy: 0.674\n",
      "Current accuracy: 0.669\n",
      "Current accuracy: 0.71\n",
      "Current accuracy: 0.735\n",
      "Current accuracy: 0.75\n",
      "Current accuracy: 0.749\n",
      "Current accuracy: 0.797\n",
      "Reached accuracy: 0.797 in 571 batches of size 64.\n",
      "Progress: 2 / 16\n",
      "Image width: 14\n",
      "Generating test data\n",
      "Number of hidden_neurons 299\n",
      "Generated FCNN with 59203 parameters\n",
      "Current accuracy: 0.656\n",
      "Current accuracy: 0.709\n",
      "Current accuracy: 0.76\n",
      "Reached accuracy: 0.76 in 489 batches of size 64.\n",
      "Progress: 3 / 16\n",
      "Image width: 16\n",
      "Generating test data\n",
      "Number of hidden_neurons 287\n",
      "Generated FCNN with 74047 parameters\n",
      "Current accuracy: 0.611\n",
      "Current accuracy: 0.676\n",
      "Current accuracy: 0.668\n",
      "Current accuracy: 0.678\n",
      "Current accuracy: 0.705\n",
      "Current accuracy: 0.742\n",
      "Current accuracy: 0.756\n",
      "Reached accuracy: 0.756 in 781 batches of size 64.\n",
      "Progress: 4 / 16\n",
      "Image width: 18\n",
      "Generating test data\n",
      "Number of hidden_neurons 280\n",
      "Generated FCNN with 91281 parameters\n",
      "Current accuracy: 0.572\n",
      "Current accuracy: 0.656\n",
      "Current accuracy: 0.667\n",
      "Current accuracy: 0.66\n",
      "Current accuracy: 0.69\n",
      "Current accuracy: 0.717\n",
      "Current accuracy: 0.741\n",
      "Current accuracy: 0.734\n",
      "Current accuracy: 0.77\n",
      "Reached accuracy: 0.77 in 874 batches of size 64.\n",
      "Progress: 5 / 16\n",
      "Image width: 20\n",
      "Generating test data\n",
      "Number of hidden_neurons 274\n",
      "Generated FCNN with 110149 parameters\n",
      "Current accuracy: 0.554\n",
      "Current accuracy: 0.671\n",
      "Current accuracy: 0.666\n",
      "Current accuracy: 0.7\n",
      "Current accuracy: 0.671\n",
      "Train loss: 1.0452333688735962\n",
      "Current accuracy: 0.713\n",
      "Current accuracy: 0.697\n",
      "Train loss: 1.0780853033065796\n",
      "Current accuracy: 0.766\n",
      "Reached accuracy: 0.766 in 1248 batches of size 64.\n",
      "Progress: 6 / 16\n",
      "Image width: 22\n",
      "Generating test data\n",
      "Number of hidden_neurons 270\n",
      "Generated FCNN with 131221 parameters\n",
      "Current accuracy: 0.495\n",
      "Current accuracy: 0.539\n",
      "Current accuracy: 0.527\n",
      "Current accuracy: 0.632\n",
      "Current accuracy: 0.723\n",
      "Current accuracy: 0.706\n",
      "Current accuracy: 0.726\n",
      "Current accuracy: 0.773\n",
      "Reached accuracy: 0.773 in 1397 batches of size 64.\n",
      "Progress: 7 / 16\n",
      "Image width: 24\n",
      "Generating test data\n",
      "Number of hidden_neurons 266\n",
      "Generated FCNN with 153749 parameters\n",
      "Train loss: 1.0637365579605103\n",
      "Current accuracy: 0.623\n",
      "Current accuracy: 0.639\n",
      "Current accuracy: 0.691\n",
      "Current accuracy: 0.682\n",
      "Current accuracy: 0.644\n",
      "Current accuracy: 0.674\n",
      "Current accuracy: 0.704\n",
      "Current accuracy: 0.761\n",
      "Reached accuracy: 0.761 in 1800 batches of size 64.\n",
      "Progress: 8 / 16\n",
      "Image width: 26\n",
      "Generating test data\n",
      "Number of hidden_neurons 264\n",
      "Generated FCNN with 178993 parameters\n",
      "Train loss: 1.1182585954666138\n",
      "Train loss: 1.0177780389785767\n",
      "Train loss: 1.0045478343963623\n",
      "Train loss: 1.0249407291412354\n",
      "Train loss: 1.0213420391082764\n",
      "Train loss: 1.0977840423583984\n",
      "Train loss: 1.1006697416305542\n",
      "Train loss: 1.0531858205795288\n",
      "Train loss: 1.0499671697616577\n",
      "Current accuracy: 0.591\n",
      "Current accuracy: 0.618\n",
      "Current accuracy: 0.6\n",
      "Current accuracy: 0.597\n",
      "Current accuracy: 0.661\n",
      "Train loss: 1.0376968383789062\n",
      "Current accuracy: 0.705\n",
      "Current accuracy: 0.711\n",
      "Current accuracy: 0.721\n",
      "Train loss: 2.302830457687378\n",
      "Current accuracy: 0.736\n",
      "Current accuracy: 0.747\n",
      "Current accuracy: 0.736\n",
      "Train loss: 2.1282005310058594\n",
      "Train loss: 2.1968305110931396\n",
      "Current accuracy: 0.752\n",
      "Reached accuracy: 0.752 in 2443 batches of size 64.\n",
      "Progress: 9 / 16\n",
      "Image width: 28\n",
      "Generating test data\n",
      "Number of hidden_neurons 262\n",
      "Generated FCNN with 205933 parameters\n",
      "Train loss: 1.0407447814941406\n",
      "Train loss: 1.1471664905548096\n",
      "Train loss: 1.0164015293121338\n",
      "Train loss: 1.0214855670928955\n",
      "Current accuracy: 0.476\n",
      "Train loss: 1.0115206241607666\n",
      "Train loss: 1.2262197732925415\n",
      "Train loss: 1.3435112237930298\n",
      "Train loss: 1.016477346420288\n",
      "Train loss: 1.0287081003189087\n",
      "Current accuracy: 0.517\n",
      "Train loss: 1.0163500308990479\n",
      "Current accuracy: 0.612\n",
      "Current accuracy: 0.609\n",
      "Current accuracy: 0.614\n",
      "Current accuracy: 0.663\n",
      "Current accuracy: 0.719\n",
      "Current accuracy: 0.693\n",
      "Current accuracy: 0.695\n",
      "Current accuracy: 0.716\n",
      "Train loss: 1.8567936420440674\n",
      "Current accuracy: 0.714\n",
      "Current accuracy: 0.743\n",
      "Current accuracy: 0.73\n",
      "Current accuracy: 0.781\n",
      "Reached accuracy: 0.781 in 2823 batches of size 64.\n",
      "Progress: 10 / 16\n",
      "Image width: 30\n",
      "Generating test data\n",
      "Number of hidden_neurons 260\n",
      "Generated FCNN with 234521 parameters\n",
      "Train loss: 1.0083866119384766\n",
      "Train loss: 1.033124566078186\n",
      "Train loss: 1.0431219339370728\n",
      "Train loss: 1.0740351676940918\n",
      "Train loss: 1.1300784349441528\n",
      "Train loss: 1.060357689857483\n",
      "Current accuracy: 0.58\n",
      "Current accuracy: 0.607\n",
      "Current accuracy: 0.613\n",
      "Train loss: 1.0118026733398438\n",
      "Current accuracy: 0.662\n",
      "Train loss: 1.0417959690093994\n",
      "Current accuracy: 0.662\n",
      "Current accuracy: 0.621\n",
      "Current accuracy: 0.673\n",
      "Current accuracy: 0.649\n",
      "Current accuracy: 0.689\n",
      "Train loss: 2.1081597805023193\n",
      "Train loss: 1.0116300582885742\n",
      "Current accuracy: 0.658\n",
      "Current accuracy: 0.701\n",
      "Current accuracy: 0.753\n",
      "Reached accuracy: 0.753 in 2926 batches of size 64.\n",
      "Progress: 11 / 16\n",
      "Image width: 32\n",
      "Generating test data\n",
      "Number of hidden_neurons 259\n",
      "Generated FCNN with 265735 parameters\n",
      "Train loss: 1.0717190504074097\n",
      "Train loss: 1.0047037601470947\n",
      "Train loss: 1.0315545797348022\n",
      "Train loss: 1.2071257829666138\n",
      "Train loss: 1.0119152069091797\n",
      "Train loss: 1.0396037101745605\n",
      "Train loss: 1.0253773927688599\n",
      "Train loss: 1.2261569499969482\n",
      "Train loss: 1.0268092155456543\n",
      "Train loss: 1.2237231731414795\n",
      "Train loss: 1.0256788730621338\n",
      "Train loss: 1.014261245727539\n",
      "Train loss: 1.091099739074707\n",
      "Train loss: 1.015249490737915\n",
      "Current accuracy: 0.477\n",
      "Current accuracy: 0.562\n",
      "Current accuracy: 0.553\n",
      "Train loss: 1.1199015378952026\n",
      "Current accuracy: 0.603\n",
      "Current accuracy: 0.59\n",
      "Current accuracy: 0.634\n",
      "Current accuracy: 0.587\n",
      "Train loss: 1.0182812213897705\n",
      "Current accuracy: 0.676\n",
      "Current accuracy: 0.641\n",
      "Current accuracy: 0.624\n",
      "Current accuracy: 0.648\n",
      "Train loss: 2.330939769744873\n",
      "Train loss: 1.042144775390625\n",
      "Current accuracy: 0.721\n",
      "Current accuracy: 0.741\n",
      "Train loss: 1.066137671470642\n",
      "Train loss: 2.029078960418701\n",
      "Train loss: 1.8979889154434204\n",
      "Train loss: 1.0084654092788696\n",
      "Train loss: 2.0822179317474365\n",
      "Current accuracy: 0.71\n",
      "Train loss: 1.9580166339874268\n",
      "Train loss: 2.1851508617401123\n",
      "Train loss: 1.0699827671051025\n",
      "Train loss: 1.7989829778671265\n",
      "Current accuracy: 0.682\n",
      "Train loss: 1.0867315530776978\n",
      "Current accuracy: 0.795\n",
      "Reached accuracy: 0.795 in 4472 batches of size 64.\n",
      "Progress: 12 / 16\n",
      "Image width: 34\n",
      "Generating test data\n",
      "Number of hidden_neurons 258\n",
      "Generated FCNN with 298765 parameters\n",
      "Train loss: 1.1211767196655273\n",
      "Train loss: 1.0023781061172485\n",
      "Train loss: 1.0894767045974731\n",
      "Train loss: 1.005765676498413\n",
      "Train loss: 1.0059287548065186\n",
      "Train loss: 1.1215991973876953\n",
      "Train loss: 1.0566966533660889\n",
      "Train loss: 1.0369606018066406\n",
      "Train loss: 1.0256515741348267\n",
      "Train loss: 1.0245417356491089\n",
      "Train loss: 1.1846411228179932\n",
      "Train loss: 1.2336843013763428\n",
      "Train loss: 1.0796473026275635\n",
      "Train loss: 1.0095877647399902\n",
      "Train loss: 1.0717878341674805\n",
      "Train loss: 1.0314966440200806\n",
      "Train loss: 1.0449939966201782\n",
      "Train loss: 1.2270861864089966\n",
      "Train loss: 1.0200005769729614\n",
      "Train loss: 1.0605453252792358\n",
      "Train loss: 1.0743244886398315\n",
      "Train loss: 1.0197625160217285\n",
      "Train loss: 1.2302565574645996\n",
      "Train loss: 1.3118886947631836\n",
      "Train loss: 1.0641181468963623\n",
      "Train loss: 1.0321950912475586\n",
      "Train loss: 1.0852009057998657\n",
      "Train loss: 1.0221772193908691\n",
      "Train loss: 1.0266823768615723\n",
      "Train loss: 1.063568115234375\n",
      "Train loss: 1.0318902730941772\n",
      "Train loss: 1.1199232339859009\n",
      "Current accuracy: 0.495\n",
      "Train loss: 1.0954985618591309\n",
      "Train loss: 1.0257744789123535\n",
      "Train loss: 1.092566967010498\n",
      "Train loss: 1.0396137237548828\n",
      "Current accuracy: 0.54\n",
      "Train loss: 1.1999187469482422\n",
      "Train loss: 1.1539833545684814\n",
      "Train loss: 1.0102176666259766\n",
      "Train loss: 1.5400099754333496\n",
      "Train loss: 1.0615756511688232\n",
      "Train loss: 1.0258160829544067\n",
      "Train loss: 1.0954066514968872\n",
      "Current accuracy: 0.547\n",
      "Train loss: 1.0434136390686035\n",
      "Train loss: 1.0729734897613525\n",
      "Train loss: 1.006371259689331\n",
      "Train loss: 1.0245260000228882\n",
      "Current accuracy: 0.646\n",
      "Train loss: 1.0276824235916138\n",
      "Current accuracy: 0.657\n",
      "Current accuracy: 0.668\n",
      "Current accuracy: 0.662\n",
      "Current accuracy: 0.683\n",
      "Train loss: 1.0233491659164429\n",
      "Current accuracy: 0.709\n",
      "Train loss: 1.0008037090301514\n",
      "Current accuracy: 0.611\n",
      "Train loss: 1.3251478672027588\n",
      "Train loss: 1.0802555084228516\n",
      "Train loss: 1.1365070343017578\n",
      "Train loss: 1.1095621585845947\n",
      "Train loss: 1.009697675704956\n",
      "Current accuracy: 0.716\n",
      "Train loss: 1.0379714965820312\n",
      "Train loss: 2.0401248931884766\n",
      "Train loss: 1.0080571174621582\n",
      "Current accuracy: 0.782\n",
      "Reached accuracy: 0.782 in 3968 batches of size 64.\n",
      "Progress: 13 / 16\n",
      "Image width: 36\n",
      "Generating test data\n",
      "Number of hidden_neurons 257\n",
      "Generated FCNN with 333587 parameters\n",
      "Train loss: 1.0064610242843628\n",
      "Train loss: 1.0254223346710205\n",
      "Train loss: 1.0876855850219727\n",
      "Train loss: 1.191653847694397\n",
      "Train loss: 1.0322425365447998\n",
      "Train loss: 1.1330379247665405\n",
      "Train loss: 1.02146315574646\n",
      "Train loss: 1.0198534727096558\n",
      "Train loss: 1.129887342453003\n",
      "Train loss: 1.0256050825119019\n",
      "Train loss: 1.2657115459442139\n",
      "Train loss: 1.0938724279403687\n",
      "Train loss: 1.0057368278503418\n",
      "Train loss: 1.0122368335723877\n",
      "Train loss: 1.007885456085205\n",
      "Train loss: 1.201427698135376\n",
      "Train loss: 1.0204187631607056\n",
      "Train loss: 1.0456035137176514\n",
      "Train loss: 1.1891913414001465\n",
      "Train loss: 1.0086923837661743\n",
      "Train loss: 1.019504427909851\n",
      "Train loss: 1.241775631904602\n",
      "Train loss: 1.2107611894607544\n",
      "Train loss: 1.0119047164916992\n",
      "Train loss: 1.0220139026641846\n",
      "Train loss: 1.1926971673965454\n",
      "Train loss: 1.1855018138885498\n",
      "Train loss: 1.0426384210586548\n",
      "Train loss: 1.174543857574463\n",
      "Train loss: 1.1335338354110718\n",
      "Train loss: 1.030155062675476\n",
      "Train loss: 1.2351220846176147\n",
      "Train loss: 1.106471300125122\n",
      "Train loss: 1.2757201194763184\n",
      "Train loss: 1.2674756050109863\n",
      "Train loss: 1.3875985145568848\n",
      "Train loss: 1.419510006904602\n",
      "Train loss: 1.0288066864013672\n",
      "Train loss: 1.0679326057434082\n",
      "Train loss: 1.1417663097381592\n",
      "Train loss: 1.0673986673355103\n",
      "Train loss: 1.0239579677581787\n",
      "Train loss: 1.0525333881378174\n",
      "Train loss: 1.0632939338684082\n",
      "Train loss: 1.1159616708755493\n",
      "Train loss: 1.0003626346588135\n",
      "Current accuracy: 0.544\n",
      "Train loss: 1.0118776559829712\n",
      "Train loss: 1.0497344732284546\n",
      "Train loss: 1.2865943908691406\n",
      "Train loss: 1.2426118850708008\n",
      "Train loss: 1.0509164333343506\n",
      "Current accuracy: 0.619\n",
      "Current accuracy: 0.581\n",
      "Train loss: 1.0353132486343384\n",
      "Train loss: 1.0296571254730225\n",
      "Current accuracy: 0.6\n",
      "Train loss: 1.2359325885772705\n",
      "Current accuracy: 0.594\n",
      "Train loss: 1.0493109226226807\n",
      "Train loss: 1.0920566320419312\n",
      "Train loss: 1.0857871770858765\n",
      "Current accuracy: 0.645\n",
      "Train loss: 2.2353744506835938\n",
      "Current accuracy: 0.695\n",
      "Train loss: 1.049797534942627\n",
      "Current accuracy: 0.68\n",
      "Train loss: 1.427330732345581\n",
      "Current accuracy: 0.708\n",
      "Train loss: 1.0715422630310059\n",
      "Train loss: 1.037330985069275\n",
      "Train loss: 1.1767247915267944\n",
      "Train loss: 2.134828567504883\n",
      "Current accuracy: 0.722\n",
      "Train loss: 2.1467137336730957\n",
      "Current accuracy: 0.734\n",
      "Train loss: 2.474705934524536\n",
      "Train loss: 2.3903651237487793\n",
      "Current accuracy: 0.765\n",
      "Reached accuracy: 0.765 in 4749 batches of size 64.\n",
      "Progress: 14 / 16\n",
      "Image width: 38\n",
      "Generating test data\n",
      "Number of hidden_neurons 256\n",
      "Generated FCNN with 370177 parameters\n",
      "Train loss: 1.0222768783569336\n",
      "Train loss: 1.004399299621582\n",
      "Train loss: 1.1145738363265991\n",
      "Train loss: 1.0775831937789917\n",
      "Train loss: 1.014116644859314\n",
      "Train loss: 1.0682440996170044\n",
      "Train loss: 1.0010595321655273\n",
      "Train loss: 1.0795913934707642\n",
      "Train loss: 1.0231786966323853\n",
      "Train loss: 1.0178627967834473\n",
      "Train loss: 1.0533841848373413\n",
      "Train loss: 1.2111417055130005\n",
      "Train loss: 1.0056049823760986\n",
      "Train loss: 1.030596375465393\n",
      "Train loss: 1.0335605144500732\n",
      "Train loss: 1.033329963684082\n",
      "Train loss: 1.021674394607544\n",
      "Train loss: 1.059073805809021\n",
      "Train loss: 1.0876586437225342\n",
      "Train loss: 1.1369487047195435\n",
      "Train loss: 1.343288779258728\n",
      "Train loss: 1.1814264059066772\n",
      "Train loss: 1.3554202318191528\n",
      "Train loss: 1.0967693328857422\n",
      "Train loss: 1.0368231534957886\n",
      "Train loss: 1.026853322982788\n",
      "Train loss: 1.0166445970535278\n",
      "Train loss: 1.0126547813415527\n",
      "Train loss: 1.0627772808074951\n",
      "Train loss: 1.1541500091552734\n",
      "Train loss: 1.1461743116378784\n",
      "Train loss: 1.0582404136657715\n",
      "Train loss: 1.0161793231964111\n",
      "Train loss: 1.0888612270355225\n",
      "Train loss: 1.3057066202163696\n",
      "Train loss: 1.1577327251434326\n",
      "Train loss: 1.0076318979263306\n",
      "Train loss: 1.0212000608444214\n",
      "Train loss: 1.0298426151275635\n",
      "Train loss: 1.1072596311569214\n",
      "Train loss: 1.0195016860961914\n",
      "Train loss: 1.1269608736038208\n",
      "Train loss: 1.1220675706863403\n",
      "Train loss: 1.0232524871826172\n",
      "Train loss: 1.0319645404815674\n",
      "Train loss: 1.0017169713974\n",
      "Train loss: 1.0272371768951416\n",
      "Train loss: 1.0028347969055176\n",
      "Train loss: 1.0217195749282837\n",
      "Train loss: 1.1272982358932495\n",
      "Train loss: 1.0764840841293335\n",
      "Train loss: 1.1959562301635742\n",
      "Train loss: 1.009055733680725\n",
      "Train loss: 1.0119354724884033\n",
      "Train loss: 1.019272804260254\n",
      "Train loss: 1.0849376916885376\n",
      "Train loss: 1.0704265832901\n",
      "Current accuracy: 0.779\n",
      "Reached accuracy: 0.779 in 3041 batches of size 64.\n",
      "Progress: 15 / 16\n",
      "Image width: 40\n",
      "Generating test data\n",
      "Number of hidden_neurons 256\n",
      "Generated FCNN with 410113 parameters\n",
      "Train loss: 1.0060738325119019\n",
      "Train loss: 1.1384738683700562\n",
      "Train loss: 1.0152803659439087\n",
      "Train loss: 1.0832136869430542\n",
      "Train loss: 1.055748701095581\n",
      "Train loss: 1.0510509014129639\n",
      "Train loss: 1.0272883176803589\n",
      "Train loss: 1.1348682641983032\n",
      "Train loss: 1.0557492971420288\n",
      "Train loss: 1.0319392681121826\n",
      "Train loss: 1.0124058723449707\n",
      "Train loss: 1.0462312698364258\n",
      "Train loss: 1.0624659061431885\n",
      "Train loss: 1.043221116065979\n",
      "Train loss: 1.1853387355804443\n",
      "Train loss: 1.0250577926635742\n",
      "Train loss: 1.1158206462860107\n",
      "Train loss: 1.0059795379638672\n",
      "Train loss: 1.0279161930084229\n",
      "Train loss: 1.0038491487503052\n",
      "Train loss: 1.0264763832092285\n",
      "Train loss: 1.1352938413619995\n",
      "Train loss: 1.107404112815857\n",
      "Train loss: 1.0043243169784546\n",
      "Train loss: 1.0015562772750854\n",
      "Train loss: 1.0064523220062256\n",
      "Train loss: 1.0272164344787598\n",
      "Train loss: 1.2441864013671875\n",
      "Train loss: 1.1397590637207031\n",
      "Train loss: 1.0415014028549194\n",
      "Train loss: 1.0874844789505005\n",
      "Train loss: 1.0845978260040283\n",
      "Train loss: 1.004996418952942\n",
      "Train loss: 1.0516265630722046\n",
      "Train loss: 1.036449909210205\n",
      "Train loss: 1.0633573532104492\n",
      "Train loss: 1.0734806060791016\n",
      "Train loss: 1.0650746822357178\n",
      "Train loss: 1.06889009475708\n",
      "Train loss: 1.001904010772705\n",
      "Train loss: 1.0594151020050049\n",
      "Train loss: 1.0934900045394897\n",
      "Train loss: 1.0447585582733154\n",
      "Train loss: 1.0299959182739258\n",
      "Train loss: 1.0689183473587036\n",
      "Train loss: 1.0727617740631104\n",
      "Train loss: 1.0769730806350708\n",
      "Train loss: 1.072677493095398\n",
      "Train loss: 1.0076634883880615\n",
      "Train loss: 1.0450763702392578\n",
      "Train loss: 1.0017426013946533\n",
      "Train loss: 1.1366678476333618\n",
      "Train loss: 1.068114995956421\n",
      "Current accuracy: 0.52\n",
      "Train loss: 1.2384132146835327\n",
      "Train loss: 1.2367498874664307\n",
      "Train loss: 1.0033764839172363\n",
      "Train loss: 1.1058077812194824\n",
      "Train loss: 1.1340510845184326\n",
      "Train loss: 1.132322072982788\n",
      "Train loss: 1.3092113733291626\n",
      "Train loss: 1.0891258716583252\n",
      "Train loss: 1.0281463861465454\n",
      "Train loss: 1.0623631477355957\n",
      "Train loss: 1.002914309501648\n",
      "Train loss: 1.0419973134994507\n",
      "Current accuracy: 0.547\n",
      "Train loss: 1.0020709037780762\n",
      "Train loss: 1.0655890703201294\n",
      "Train loss: 1.1579833030700684\n",
      "Train loss: 1.1017793416976929\n",
      "Train loss: 1.0841448307037354\n",
      "Train loss: 1.0396530628204346\n",
      "Train loss: 1.0990519523620605\n",
      "Train loss: 1.1005542278289795\n",
      "Train loss: 1.0585582256317139\n",
      "Train loss: 1.2783732414245605\n",
      "Train loss: 1.0119659900665283\n",
      "Train loss: 1.2779444456100464\n",
      "Train loss: 1.0083891153335571\n",
      "Train loss: 1.0791387557983398\n",
      "Train loss: 1.0039244890213013\n",
      "Train loss: 1.1167556047439575\n",
      "Train loss: 1.0127201080322266\n",
      "Current accuracy: 0.549\n",
      "Train loss: 1.0108561515808105\n",
      "Train loss: 1.0278252363204956\n",
      "Train loss: 1.0082989931106567\n",
      "Current accuracy: 0.528\n",
      "Train loss: 1.676875352859497\n",
      "Train loss: 1.337064266204834\n",
      "Train loss: 1.0316448211669922\n",
      "Train loss: 1.2159504890441895\n",
      "Train loss: 1.3305909633636475\n",
      "Train loss: 1.2608282566070557\n",
      "Train loss: 1.0277626514434814\n",
      "Train loss: 1.008853554725647\n",
      "Train loss: 1.2296364307403564\n",
      "Train loss: 1.0582387447357178\n",
      "Train loss: 1.1317791938781738\n",
      "Train loss: 1.1298893690109253\n",
      "Train loss: 1.2890267372131348\n",
      "Current accuracy: 0.612\n",
      "Train loss: 1.042153239250183\n",
      "Train loss: 1.0659940242767334\n",
      "Train loss: 1.0156478881835938\n",
      "Train loss: 1.0198845863342285\n",
      "Current accuracy: 0.625\n",
      "Train loss: 1.1984784603118896\n",
      "Train loss: 1.1282470226287842\n",
      "Train loss: 1.0561105012893677\n",
      "Train loss: 1.0810422897338867\n",
      "Train loss: 1.0411051511764526\n",
      "Current accuracy: 0.665\n",
      "Train loss: 1.002534031867981\n",
      "Current accuracy: 0.69\n",
      "Current accuracy: 0.683\n",
      "Train loss: 1.1679396629333496\n",
      "Train loss: 1.0273069143295288\n",
      "Current accuracy: 0.726\n",
      "Current accuracy: 0.65\n",
      "Train loss: 1.0333354473114014\n",
      "Train loss: 1.2574681043624878\n",
      "Train loss: 1.06968355178833\n",
      "Current accuracy: 0.614\n",
      "Train loss: 1.1762986183166504\n",
      "Train loss: 1.6655800342559814\n",
      "Train loss: 1.0192950963974\n",
      "Train loss: 1.028525948524475\n",
      "Train loss: 1.1095554828643799\n",
      "Train loss: 1.0358353853225708\n",
      "Train loss: 1.2272309064865112\n",
      "Train loss: 1.0283000469207764\n",
      "Current accuracy: 0.706\n",
      "Train loss: 1.1202001571655273\n",
      "Train loss: 1.0885032415390015\n",
      "Train loss: 1.0122421979904175\n",
      "Current accuracy: 0.655\n",
      "Train loss: 1.1591999530792236\n",
      "Train loss: 1.2734155654907227\n",
      "Train loss: 1.1805317401885986\n",
      "Train loss: 1.010436773300171\n",
      "Train loss: 1.1060340404510498\n",
      "Train loss: 1.0124529600143433\n",
      "Train loss: 1.0724067687988281\n",
      "Train loss: 1.0081572532653809\n",
      "Train loss: 1.1116228103637695\n",
      "Train loss: 2.056562900543213\n",
      "Train loss: 1.9233121871948242\n",
      "Train loss: 1.0200932025909424\n",
      "Train loss: 2.2577388286590576\n",
      "Train loss: 1.9764562845230103\n",
      "Train loss: 2.202727794647217\n",
      "Train loss: 1.0190073251724243\n",
      "Train loss: 1.0388734340667725\n",
      "Current accuracy: 0.745\n",
      "Train loss: 2.185976266860962\n",
      "Train loss: 3.5154130458831787\n",
      "Train loss: 2.4423718452453613\n",
      "Train loss: 1.9463542699813843\n",
      "Train loss: 2.4294731616973877\n",
      "Train loss: 2.42645525932312\n",
      "Train loss: 2.158470392227173\n",
      "Current accuracy: 0.776\n",
      "Reached accuracy: 0.776 in 7473 batches of size 64.\n",
      "Progress: 16 / 16\n"
     ]
    }
   ],
   "source": [
    "# Reset number generation\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Perform the experiment multiple times\n",
    "for _ in range(estimates):\n",
    "\n",
    "    # Model loader\n",
    "    loader = ModelLoader()\n",
    "\n",
    "    # Input shape\n",
    "    channels = 1\n",
    "    img_sides = np.arange(min_w, max_w+1, skip_w) # Image side lengths\n",
    "    input_dims = channels*img_sides**2 # Input dimension\n",
    "    input_shapes = [(channels, img_size, img_size) for img_size in img_sides]\n",
    "\n",
    "    # Create dataset images\n",
    "    for i, l in enumerate(img_sides):\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Image width: {l}\")\n",
    "\n",
    "        # Generate dataset and dataloaders\n",
    "        print(f\"Generating test data\")\n",
    "        clamp_ = l//2 if relative else clamp\n",
    "        \n",
    "        x_te, y_te, _ = gen_pattern_xy(l, channels, N_te, freq, clamp_)\n",
    "        te_loader = DataLoader(TensorDataset(x_te, y_te), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # Load model\n",
    "        \n",
    "        model_options = {'input_shape': input_shapes[i], 'out_channels': cnn_out_chans}\n",
    "\n",
    "        # Parameter-fair FCNN options\n",
    "        if architecture == \"FCNN\":\n",
    "            \n",
    "            # Create reference CNN\n",
    "            cnn = loader.load(\"CNN\", \"ReLU\", {'input_shape': input_shapes[i], 'out_channels': cnn_out_chans})\n",
    "            cnn_param_count = sum(p.numel() for p in cnn.parameters())\n",
    "            hidden_neurons = max(1, int(cnn_param_count / (input_dims[i]+1)))\n",
    "            print(\"Number of hidden_neurons\", hidden_neurons)\n",
    "\n",
    "            # Set number of hidden neurons to match CNN\n",
    "            model_options['hidden_neurons'] = hidden_neurons\n",
    "\n",
    "        model = loader.load(architecture, activation, model_options).to(device)\n",
    "\n",
    "        # Print number of parameters\n",
    "        print(\"Generated\", architecture, \"with\", count_parameters(model), \"parameters\")\n",
    "        \n",
    "        # Optimizer and criterion\n",
    "        optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        tr_loss_req = 0.5\n",
    "        tr_step = 0\n",
    "        while True:\n",
    "            model.train()\n",
    "            x_tr, y_tr, _ = gen_pattern_xy(l, channels, batch_size, freq, clamp_)\n",
    "            batch_x, batch_y = x_tr.to(device), y_tr.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_x)\n",
    "            tr_loss = criterion(output, batch_y)\n",
    "            \n",
    "            tr_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print if unstable\n",
    "            if tr_loss.item() > 1:\n",
    "                print(\"Train loss:\", tr_loss.item())\n",
    "\n",
    "            # Evaluate (when tr_loss is small)\n",
    "            accuracy = 0.0\n",
    "            \n",
    "            if tr_loss.item() < tr_loss_req:\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    for batch_x, batch_y in te_loader:\n",
    "                        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                        output = model(batch_x)\n",
    "                        accuracy += sum(torch.eq((output>0.5).to(float), batch_y)).item()\n",
    "                    accuracy /= N_te\n",
    "                print(f\"Current accuracy: {accuracy}\")\n",
    "                tr_loss_req = max(0.01, tr_loss_req - 0.025)\n",
    "\n",
    "            # Check goal\n",
    "            tr_step += 1\n",
    "            if accuracy > epsilon:\n",
    "                print(f\"Reached accuracy: {accuracy} in {tr_step} batches of size {batch_size}.\")\n",
    "                break\n",
    "\n",
    "        # Save results\n",
    "        with open(filepath, 'rb') as file:\n",
    "            results = pickle.load(file)\n",
    "\n",
    "        # Add experiment to results\n",
    "        results[(arch_name, input_dims[i])] = (results.get((arch_name, input_dims[i])) or []) + [tr_step * batch_size]\n",
    "\n",
    "        # Write training set size to file\n",
    "        with open(filepath, 'wb') as file:\n",
    "            pickle.dump(results, file)\n",
    "            \n",
    "        # Print progress\n",
    "        print(f\"Progress: {i +1} / {(max_w - min_w) // skip_w + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial fitting\n",
    "\n",
    "Now we perform parameter fitting on both curves. To simplify the fit, we assume that the y-axis intercept is 0, and that the coefficients and degree are positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we perform polynomial parameter estimation\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# The function to fit\n",
    "def polynomial(x, a, b):\n",
    "    return a*(x**b)\n",
    "\n",
    "# The bounds on the coefficients\n",
    "bounds = (0, np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_and_aggregate(results, model_name, ops):\n",
    "    \n",
    "    # Unzipped lists\n",
    "    xs, ys = list(zip(*sorted([(int((dim)**0.5), tr_size) for (_name, dim), tr_size  in results.items() if model_name == _name])))\n",
    "\n",
    "    # Format lists for scattering\n",
    "    xs_rep = []\n",
    "    for i, y in enumerate(ys):\n",
    "        xs_rep = np.concatenate([xs_rep, np.repeat(xs[i], len(y))])\n",
    "\n",
    "    ys_flat = np.array(ys).flatten()\n",
    "\n",
    "    # Operations\n",
    "    results = [[op(y) for y in ys] for op in ops]\n",
    "\n",
    "    return xs_rep, ys_flat, *tuple(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "with open(filepath, 'rb') as file:\n",
    "    sample_complexity = pickle.load(file)\n",
    "# Extract data to plot\n",
    "names = set([name for name, _ in sample_complexity.keys()])\n",
    "\n",
    "# Plot colours\n",
    "colors = ['tab:blue', 'tab:orange']\n",
    "\n",
    "# For every model, make line plot\n",
    "for i, name in enumerate(names):\n",
    "    \n",
    "    xs, ys, means, stds = unpack_and_aggregate(sample_complexity, name, [np.mean, np.std])\n",
    "    plt.scatter(xs, ys, marker='.', linestyle='-', label=name, color=colors[i])\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot means and standard deviations\n",
    "    # plt.errorbar(np.unique(xs), means, stds, color=(0.5, 0.5, 0.5, 0.5))\n",
    "\n",
    "    # Plot polynomial estimates\n",
    "    fitted, covariance = curve_fit(polynomial, xs, ys, p0=[1, 1], bounds=bounds)\n",
    "    \n",
    "    plt.plot(xs, polynomial(xs, *fitted), label=\"{:.1f}+x^{:.1f}\".format(fitted[0], fitted[1]), color=colors[i])\n",
    "    plt.legend()\n",
    "\n",
    "# Plot graphics\n",
    "plt.xlabel('Image width')\n",
    "plt.ylabel('Training set size')\n",
    "plt.legend()\n",
    "plt.xticks(ticks=[tick for tick in plt.xticks()[0]][1::2], labels=[tick for tick in plt.xticks()[1]][1::2])\n",
    "plt.title(f'Adam to >{epsilon*100}% accuracy')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
