{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a91d765",
   "metadata": {},
   "source": [
    "# Sample Complexity Gap\n",
    "\n",
    "This notebook aims to demonstrate the stated sample complexity gap in **Why Are Convolutional Networks More Sample Efficient Than Fully-Connected Nets? by Zhiyuan Li, Yi Zhang and Sanjeev Arora** [1]. We set up an experiment in which we should see the gap as an increasing polynomial curve of degree less than two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95758862",
   "metadata": {},
   "source": [
    "## 1. Methods\n",
    "\n",
    "For a given input dimension $d$, we seek the number $|S_{tr}|$ of training samples needed for a model to reach $\\epsilon=0.9$ test accuracy. Then we plot the difference of training samples needed between a Convolutional Neural Network and a Fully Connected Neural Network for increasing values of $d$.\n",
    "\n",
    "### Data\n",
    "\n",
    "The inputs are $3\\times k \\times k$ RGB images for $k\\in \\mathbb{N}$, yielding input dimensions $d\\in \\{3,12,27,48,75,108,147,243,300,...\\}$. We create full training set of $10'000$ images and a test set of $10'000$ and we ask \"the first *how-many* training samples are needed to reach $90\\%$ test accuracy if we train until convergence\"? The training sets are constructed in the following manner.\n",
    "+ Entry-wise independent Gaussian (mean 0, standard deviation 1)\n",
    "\n",
    "We explore two different labelling functions \n",
    "\\begin{equation}\n",
    "h_1=\\mathbb{1}[\\sum_{i\\in R} x_i > \\sum_{i \\in G}x_i] \\quad\\mathrm{ and }\\quad h_2=\\mathbb{1}[\\sum_{i\\in R} x_i^2 > \\sum_{i \\in G}x_i^2].\n",
    "\\end{equation}\n",
    "\n",
    "### Models\n",
    "\n",
    "1. 2-layer CNN.\n",
    "    + Convolution - one kernel per input channel of size 3x3, 10 output channels, stride size 1, and padding of 1, and bias\n",
    "    + Activation function\n",
    "    + Pooling: Max pooling, kernel size 2x2, stride 2\n",
    "    + Flattening\n",
    "    + Fully connected layer (? in, 1 out) with bias\n",
    "    + Sigmoid\n",
    "2. 2-layer FCNN \n",
    "    + Fully connected layer (192 in, 3072 out) with bias\n",
    "    + Activation function \n",
    "    + Fully connected layer (3072 in, 1 out) with bias\n",
    "    + Sigmoid\n",
    "    \n",
    "We try both ReLU and Quadratic activation functions. \n",
    "\n",
    "### Training algorithm\n",
    "+ Stochastic Gradient Descent with batch size 64\n",
    "+ BCELoss\n",
    "+ Learning rate $\\gamma = 0.01$\n",
    "+ Stopping criterion: At least 10 epochs AND Training loss < 0.01 AND Rolling avg. of rel. change in training loss < 0.01 (window size 10). OR 1000 epochs.\n",
    "\n",
    "### Model Evaluation\n",
    "+ The model $M$ prediction is $\\mathbb{1}[M(x)>0.5]$. Test accuracy is the percentage of correct predictions over the test set.\n",
    "\n",
    "### Search algorithm\n",
    "\n",
    "We seek the number of training samples needed to reach a fixed test accuracy using a kind of bisection algorithm.\n",
    "1. Initial training run on 5000 samples.\n",
    "    + If test accuracy > 0.9, take half step towards 0 -> 2'500\n",
    "    + If test accuracy <= 0.9 take half step towards 10'000 -> 7500\n",
    "2. Reload initial weights and retrain. Make quarter step.\n",
    "\n",
    "This is repeated $10$ times with different weight initialisations in case the test-accuracy curves are not monotonically increasing due to noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f15390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchsummary import summary\n",
    "from json import load, dump\n",
    "\n",
    "# Local python scripts\n",
    "from helpers import roll_avg_rel_change, calc_label\n",
    "from models import CNN, FCNN, Quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bd80dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed random number generation\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8a3c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "max_epochs = 1000\n",
    "window = 10 # Window size for convergence crit.\n",
    "rel_conv_crit = 0.01\n",
    "abs_conv_crit = 0.01\n",
    "epsilon = 0.7 # Required accuracy\n",
    "\n",
    "# Input shape\n",
    "channels = 3 # RGB images\n",
    "img_sizes =  np.arange(8, 12) # Image side lengths\n",
    "input_sizes = 3*img_sizes**2 # Input dimension\n",
    "input_shapes = [(channels, img_size, img_size) for img_size in img_sizes]\n",
    "\n",
    "# Full dataset sizes\n",
    "N_tr = 10000\n",
    "N_te = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ecd94b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 [0, 100, 10000]\n"
     ]
    }
   ],
   "source": [
    "n_tried=[0, 100, 10000]\n",
    "n = 100\n",
    "if 0.5 < 0.9:\n",
    "    index = max(n_tried.index(n)-1, 0)\n",
    "else:\n",
    "    if n_tried.index(n)==len(n_tried)-1:\n",
    "        n_tried+=[n_tried[-1]*2]\n",
    "    else:\n",
    "        n += (n_tried[-1] - n) / 2\n",
    "        \n",
    "print(n, n_tried)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec02b1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension: 192\n",
      "CNNquad\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1             [-1, 10, 8, 8]             280\n",
      "         Quadratic-2             [-1, 10, 8, 8]               0\n",
      "         MaxPool2d-3             [-1, 10, 4, 4]               0\n",
      "           Sigmoid-4                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 280\n",
      "Trainable params: 280\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n",
      "Iterate  0 Training samples:  100\n",
      "Epoch: 100 Loss:  0.728851854801178\n",
      "Epoch: 200 Loss:  0.7228296995162964\n",
      "Epoch: 300 Loss:  0.7010923624038696\n",
      "Epoch: 400 Loss:  0.689973771572113\n",
      "Epoch: 500 Loss:  0.6737563610076904\n",
      "Epoch: 600 Loss:  0.6960011124610901\n",
      "Epoch: 700 Loss:  0.689094603061676\n",
      "Epoch: 800 Loss:  0.7395244240760803\n",
      "Epoch: 900 Loss:  0.7077314853668213\n",
      "Epoch: 1000 Loss:  0.7056445479393005\n",
      "Finished training:  1001  Acc:  0.4909000098705292\n",
      "Iterate  1 Training samples:  5050\n",
      "Epoch: 100 Loss:  0.6923936605453491\n",
      "Epoch: 200 Loss:  0.6916697025299072\n",
      "Epoch: 300 Loss:  0.6956424117088318\n",
      "Epoch: 400 Loss:  0.695265531539917\n",
      "Epoch: 500 Loss:  0.6893059015274048\n",
      "Epoch: 600 Loss:  0.6973016858100891\n",
      "Epoch: 700 Loss:  0.6964520812034607\n",
      "Epoch: 800 Loss:  0.6925011873245239\n",
      "Epoch: 900 Loss:  0.691730260848999\n",
      "Epoch: 1000 Loss:  0.6938693523406982\n",
      "Finished training:  1001  Acc:  0.5016000270843506\n",
      "Iterate  2 Training samples:  6287\n",
      "Epoch: 100 Loss:  0.6960862874984741\n",
      "Epoch: 200 Loss:  0.6935973763465881\n",
      "Epoch: 300 Loss:  0.6978158354759216\n",
      "Epoch: 400 Loss:  0.691579282283783\n",
      "Epoch: 500 Loss:  0.6927477121353149\n",
      "Epoch: 600 Loss:  0.6980549097061157\n",
      "Epoch: 700 Loss:  0.698024332523346\n",
      "Epoch: 800 Loss:  0.6936750411987305\n",
      "Epoch: 900 Loss:  0.690270185470581\n",
      "Epoch: 1000 Loss:  0.706436038017273\n",
      "Finished training:  1001  Acc:  0.4984000027179718\n",
      "Iterate  3 Training samples:  6751\n",
      "Epoch: 100 Loss:  0.6978145837783813\n",
      "Epoch: 200 Loss:  0.6931145787239075\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, batch_y)\n\u001b[0;32m     50\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 51\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Check for convergence\u001b[39;00m\n\u001b[0;32m     54\u001b[0m roll_avg \u001b[38;5;241m=\u001b[39m roll_avg_rel_change(loss_queue, window, loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\optim\\optimizer.py:112\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m obj, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m args\n\u001b[0;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile_name\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\autograd\\profiler.py:443\u001b[0m, in \u001b[0;36mrecord_function.__init__\u001b[1;34m(self, name, args)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks_on_exit: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;66;03m# Stores underlying RecordFunction as a tensor. TODO: move to custom\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;66;03m# class (https://github.com/pytorch/pytorch/issues/35026).\u001b[39;00m\n\u001b[1;32m--> 443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# For increasing input dimension\n",
    "for i, d in enumerate(input_sizes):\n",
    "    \n",
    "    print(f\"Input dimension: {d}\")\n",
    "    \n",
    "    # Full training and test sets\n",
    "    gauss_x_tr = torch.tensor(np.random.normal(0,1,size=(N_tr,*(input_shapes[i]))),dtype=torch.float32)\n",
    "    gauss_x_te = torch.tensor(np.random.normal(0,1,size=(N_te,*(input_shapes[i]))),dtype=torch.float32)\n",
    "\n",
    "    # Full h2 training and test labels (Replace with p=1 for h1)\n",
    "    gauss_y_tr = calc_label(gauss_x_tr, p=2)\n",
    "    gauss_y_te = calc_label(gauss_x_te, p=2)\n",
    "    \n",
    "    # Models\n",
    "    models = [CNN(Quadratic()), FCNN(d, Quadratic())]\n",
    "    names = ['CNNquad', 'FCNNquad']\n",
    "    for j, model in enumerate(models):\n",
    "        print(names[j])\n",
    "        summary(model, input_shapes[i])\n",
    "        torch.save(model.state_dict(), 'Weights/'+names[j]+'.pth')\n",
    "        \n",
    "        # Find correct training sample set size by bisection\n",
    "        n = 100 # Number of training samples\n",
    "        found = False\n",
    "        n_tried = [n]\n",
    "        while not found:\n",
    "            print(\"Iterate \", iterate, \"Training samples: \", n)\n",
    "            \n",
    "            # Reset models\n",
    "            model.load_state_dict(torch.load('Weights/'+names[j]+'.pth'))\n",
    "            \n",
    "            # Create dataloaders\n",
    "            dataset = TensorDataset(gauss_x_tr[:n], gauss_y_tr[:n])\n",
    "            dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            # Optimizer\n",
    "            optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "            \n",
    "            # Training loop\n",
    "            criterion = nn.BCELoss()\n",
    "            model.train()\n",
    "            epoch = 0\n",
    "            converged = False\n",
    "            loss_queue = [] # For rolling training loss stop criterion\n",
    "            while not converged:\n",
    "                for batch_x, batch_y in dataloader:\n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(batch_x)\n",
    "                    loss = criterion(output, batch_y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # Check for convergence\n",
    "                    roll_avg = roll_avg_rel_change(loss_queue, window, loss.item())\n",
    "                    if (roll_avg and roll_avg < rel_conv_crit and loss < abs_conv_crit) or epoch == max_epochs:\n",
    "                        converged = True\n",
    "                        break\n",
    "                \n",
    "                epoch += 1\n",
    "                if (epoch%100==0):\n",
    "                    print(\"Epoch:\", epoch, \"Loss: \", loss.item())\n",
    "            \n",
    "            # Evaluate model\n",
    "            model.eval()\n",
    "            out = model(gauss_x_te)\n",
    "            test_loss = criterion(out, gauss_y_te)\n",
    "            accuracy = float(sum(torch.eq((out > 0.5).to(float), gauss_y_te)) / N_te)\n",
    "            found = abs(accuracy - epsilon) < 0.1\n",
    "            \n",
    "            print(\"Finished training: \", epoch, \" Acc: \", accuracy)\n",
    "            \n",
    "            # Bisection method for finding correct training set size\n",
    "            iterate += 1\n",
    "            if accuracy < epsilon:\n",
    "                \n",
    "            else:\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a355c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON file\n",
    "file_path = 'test_acc.json'\n",
    "with open(file_path, 'r') as json_file:\n",
    "    test_acc = load(json_file)\n",
    "\n",
    "# Add experiment to results\n",
    "test_acc[str(N)]=accuracy\n",
    "\n",
    "# Write accuracy to file\n",
    "with open(file_path, 'w') as json_file:\n",
    "        dump(test_acc, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a6a808",
   "metadata": {},
   "source": [
    "1. [Why Are Convolutional Nets More Sample-Efficient than Fully-Connected Nets?](https://arxiv.org/abs/2010.08515) Zhiyuan Li, Yi Zhang, Sanjeev Arora, 2021"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
