{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a91d765",
   "metadata": {},
   "source": [
    "# Sample Complexity Gap\n",
    "\n",
    "This notebook aims to demonstrate the stated sample complexity gap in **Why Are Convolutional Networks More Sample Efficient Than Fully-Connected Nets? by Zhiyuan Li, Yi Zhang and Sanjeev Arora** [1]. We set up an experiment in which we should see the gap as an increasing polynomial curve of degree less than two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95758862",
   "metadata": {},
   "source": [
    "## 1. Methods\n",
    "\n",
    "For a given input dimension $d$, we seek the number $|S_{tr}|$ of training samples needed for a model to reach $\\epsilon=0.9$ test accuracy. Then we plot the difference of training samples needed between a Convolutional Neural Network and a Fully Connected Neural Network for increasing values of $d$.\n",
    "\n",
    "### Data\n",
    "\n",
    "The inputs are $3\\times k \\times k$ RGB images for $k\\in \\mathbb{N}$, yielding input dimensions $d\\in \\{..., 192, 243, 300, 363, ...\\}$. We create full training set of 10000 images and a test set of 10'000 and we ask \"the first *how-many* training samples are needed to reach $90\\%$ test accuracy if we train until convergence\"? The training sets are constructed in the following manner.\n",
    "+ Entry-wise independent Gaussian (mean 0, standard deviation 1)\n",
    "\n",
    "We explore two different labelling functions \n",
    "\\begin{equation}\n",
    "h_1=\\mathbb{1}[\\sum_{i\\in R} x_i > \\sum_{i \\in G}x_i] \\quad\\mathrm{ and }\\quad h_2=\\mathbb{1}[\\sum_{i\\in R} x_i^2 > \\sum_{i \\in G}x_i^2].\n",
    "\\end{equation}\n",
    "\n",
    "### Models\n",
    "\n",
    "1. 2-layer CNN.\n",
    "    + Convolution - one kernel per input channel of size 3x3, 10 output channels, stride size 1, and padding of 1, and bias\n",
    "    + Activation function\n",
    "    + Pooling: Max pooling, kernel size 2x2, stride 2\n",
    "    + Flattening\n",
    "    + Fully connected layer (? in, 1 out) with bias\n",
    "    + Sigmoid\n",
    "2. 2-layer FCNN \n",
    "    + Fully connected layer (192 in, 3072 out) with bias\n",
    "    + Activation function \n",
    "    + Fully connected layer (3072 in, 1 out) with bias\n",
    "    + Sigmoid\n",
    "    \n",
    "We try both ReLU and Quadratic activation functions. \n",
    "\n",
    "### Training algorithm\n",
    "+ Stochastic Gradient Descent with batch size 64\n",
    "+ BCELoss\n",
    "+ Learning rate $\\gamma = 0.01$\n",
    "+ Stopping criterion: At least 10 epochs AND Training loss < 0.01 AND Rolling avg. of rel. change in training loss < 0.01 (window size 10). OR 500 epochs.\n",
    "\n",
    "### Model Evaluation\n",
    "+ The model $M$ prediction is $\\mathbb{1}[M(x)>0.5]$. Test accuracy is the percentage of correct predictions over the test set.\n",
    "\n",
    "### Search algorithm\n",
    "\n",
    "We seek the number of training samples needed to reach a fixed test accuracy using a kind of bisection algorithm.\n",
    "1. Initial training run on 5000 samples.\n",
    "    + If test accuracy > 0.9, take half step towards 0 -> 2'500\n",
    "    + If test accuracy <= 0.9 take half step towards 10'000 -> 7500\n",
    "2. Reload initial weights and retrain. Make quarter step.\n",
    "\n",
    "This is repeated $10$ times with different weight initialisations in case the test-accuracy curves are not monotonically increasing due to noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f15390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchsummary import summary\n",
    "from json import load, dump\n",
    "\n",
    "# Local python scripts\n",
    "from helpers import roll_avg_rel_change, calc_label\n",
    "from models import CNN, FCNN, Quadratic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bd80dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed random number generation\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8a3c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global constants\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "max_epochs = 500\n",
    "window = 10 # Window size for convergence crit.\n",
    "rel_conv_crit = 0.01\n",
    "abs_conv_crit = 0.01\n",
    "epsilon = 0.9 # Required accuracy\n",
    "tolerance = 0.01 # Required tolerance\n",
    "\n",
    "# Input shape\n",
    "channels = 3 # RGB images\n",
    "img_sizes =  np.arange(4, 14) # Image side lengths\n",
    "input_sizes = 3*img_sizes**2 # Input dimension\n",
    "input_shapes = [(channels, img_size, img_size) for img_size in img_sizes]\n",
    "\n",
    "# Full dataset sizes\n",
    "N_tr = 1000000\n",
    "N_te = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47887405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec02b1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension: 48\n",
      "2-CNN+ReLU\n",
      "Iterate  1 Training samples:  100\n",
      "Finished training:  501  Acc:  0.598800003528595\n",
      "Iterate  2 Training samples:  200\n",
      "Finished training:  501  Acc:  0.6995000243186951\n",
      "Iterate  3 Training samples:  400\n",
      "Finished training:  501  Acc:  0.739799976348877\n",
      "Iterate  4 Training samples:  800\n",
      "Finished training:  501  Acc:  0.7900999784469604\n",
      "Iterate  5 Training samples:  1600\n",
      "Finished training:  501  Acc:  0.8418999910354614\n",
      "Iterate  6 Training samples:  3200\n",
      "Finished training:  501  Acc:  0.8809999823570251\n",
      "Iterate  7 Training samples:  6400\n",
      "Finished training:  501  Acc:  0.8988000154495239\n",
      "2-CNN+Quadratic\n",
      "Iterate  1 Training samples:  100\n",
      "Finished training:  501  Acc:  0.5504000186920166\n",
      "Iterate  2 Training samples:  200\n",
      "Finished training:  501  Acc:  0.6757000088691711\n",
      "Iterate  3 Training samples:  400\n",
      "Finished training:  501  Acc:  0.7797999978065491\n",
      "Iterate  4 Training samples:  800\n",
      "Finished training:  501  Acc:  0.8367000222206116\n",
      "Iterate  5 Training samples:  1600\n",
      "Finished training:  501  Acc:  0.861299991607666\n",
      "Iterate  6 Training samples:  3200\n",
      "Finished training:  501  Acc:  0.8880000114440918\n",
      "Iterate  7 Training samples:  6400\n",
      "Finished training:  501  Acc:  0.9125999808311462\n",
      "Iterate  8 Training samples:  4800\n",
      "Finished training:  501  Acc:  0.9039000272750854\n",
      "2-FCNN+ReLU\n",
      "Iterate  1 Training samples:  100\n",
      "Finished training:  501  Acc:  0.5023999810218811\n",
      "Iterate  2 Training samples:  200\n",
      "Finished training:  501  Acc:  0.5121999979019165\n",
      "Iterate  3 Training samples:  400\n",
      "Finished training:  501  Acc:  0.5461000204086304\n",
      "Iterate  4 Training samples:  800\n",
      "Finished training:  501  Acc:  0.6062999963760376\n",
      "Iterate  5 Training samples:  1600\n",
      "Finished training:  501  Acc:  0.6977999806404114\n",
      "Iterate  6 Training samples:  3200\n",
      "Finished training:  501  Acc:  0.802299976348877\n",
      "Iterate  7 Training samples:  6400\n",
      "Finished training:  501  Acc:  0.886900007724762\n",
      "Iterate  8 Training samples:  12800\n",
      "Finished training:  501  Acc:  0.9302999973297119\n",
      "Iterate  9 Training samples:  9600\n",
      "Finished training:  501  Acc:  0.9164999723434448\n",
      "Iterate  10 Training samples:  8000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m loss_queue \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m# For rolling training loss stop criterion\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m converged:\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_x, batch_y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     54\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     55\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(batch_x)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtransposed\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# For increasing input dimension\n",
    "for i, input_size in enumerate(input_sizes):\n",
    "    \n",
    "    print(f\"Input dimension: {input_size}\")\n",
    "    \n",
    "    # Full training and test sets\n",
    "    gauss_x_tr = torch.tensor(np.random.normal(0,1,size=(N_tr,*(input_shapes[i]))),dtype=torch.float32)\n",
    "    gauss_x_te = torch.tensor(np.random.normal(0,1,size=(N_te,*(input_shapes[i]))),dtype=torch.float32)\n",
    "\n",
    "    # Full h2 training and test labels (Replace with p=1 for h1)\n",
    "    gauss_y_tr = calc_label(gauss_x_tr, p=2)\n",
    "    gauss_y_te = calc_label(gauss_x_te, p=2)\n",
    "    \n",
    "    # Models\n",
    "    CNNreLU, CNNquad = CNN(input_shapes[i], nn.ReLU()), CNN(input_shapes[i], Quadratic())\n",
    "    FCNNreLU, FCNNquad = FCNN(input_size, nn.ReLU()), FCNN(input_size, Quadratic())\n",
    "    models = [CNNreLU, CNNquad, FCNNreLU, FCNNquad]\n",
    "    names = [\"2-CNN+ReLU\", \"2-CNN+Quadratic\",\"2-FCNN+ReLU\",\"2-FCNN+Quadratic\"]\n",
    "    \n",
    "    # Found training sample set sizes\n",
    "    ns = [0 for model in models]\n",
    "    \n",
    "    for j, model in enumerate(models):\n",
    "        print(names[j])\n",
    "        # summary(model, input_shapes[i])\n",
    "        torch.save(model.state_dict(), 'Weights/'+names[j]+'.pth')\n",
    "        \n",
    "        # Find exact training sample set size by bisection\n",
    "        n = 100 # Initial number of training samples\n",
    "        found = False\n",
    "        n_tried = [0]\n",
    "        iterate=1\n",
    "        while not found:\n",
    "            print(\"Iterate \", iterate, \"Training samples: \", n)\n",
    "            \n",
    "            # Reset model\n",
    "            model.load_state_dict(torch.load('weights/'+names[j]+'.pth'))\n",
    "            \n",
    "            # Create dataloaders\n",
    "            dataset = TensorDataset(gauss_x_tr[:n], gauss_y_tr[:n])\n",
    "            dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            # Optimizer\n",
    "            optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "            \n",
    "            # Training loop\n",
    "            criterion = nn.BCELoss()\n",
    "            model.train()\n",
    "            epoch = 0\n",
    "            converged = False\n",
    "            loss_queue = [] # For rolling training loss stop criterion\n",
    "            while not converged:\n",
    "                for batch_x, batch_y in dataloader:\n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(batch_x)\n",
    "                    loss = criterion(output, batch_y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # Check for convergence\n",
    "                    roll_avg = roll_avg_rel_change(loss_queue, window, loss.item())\n",
    "                    if (roll_avg and roll_avg < rel_conv_crit and loss < abs_conv_crit) or epoch == max_epochs:\n",
    "                        converged = True\n",
    "                        break\n",
    "                \n",
    "                epoch += 1\n",
    "            \n",
    "            # Evaluate model\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                out = model(gauss_x_te)\n",
    "                test_loss = criterion(out, gauss_y_te)\n",
    "                accuracy = float(sum(torch.eq((out > 0.5).to(float), gauss_y_te)) / N_te)\n",
    "                found = abs(accuracy - epsilon) < tolerance\n",
    "                \n",
    "                # Save this training set size\n",
    "                if found:\n",
    "                    ns[j]=n\n",
    "                    \n",
    "            print(\"Finished training: \", epoch, \" Acc: \", accuracy)\n",
    "            \n",
    "            # Bisection method for finding correct training set size\n",
    "            n_tried+=[n]\n",
    "            n_tried.sort()\n",
    "            idx = n_tried.index(n)\n",
    "            if accuracy > epsilon:\n",
    "                n = n // 2 if idx == 0 else (n + n_tried[idx-1]) // 2\n",
    "            else:\n",
    "                n = 2 * n if idx == len(n_tried)-1 else (n + n_tried[idx+1]) // 2\n",
    "                \n",
    "            # Try again with a different number of training samples\n",
    "            iterate += 1\n",
    "    \n",
    "    # Read the JSON file\n",
    "    file_path = 'trainset_sizes.json'\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        trainset_sizes = load(json_file)\n",
    "\n",
    "    # Add experiment to results\n",
    "    trainset_sizes[str(input_size)]=ns\n",
    "\n",
    "    # Write training set size to file\n",
    "    with open(file_path, 'w') as json_file:\n",
    "            dump(trainset_sizes, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a355c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "file_path = 'trainset_sizes.json'\n",
    "with open(file_path, 'r') as json_file:\n",
    "    test_acc = load(json_file)\n",
    "\n",
    "# Create sorted dictionary out of saved data\n",
    "new_dict = {}\n",
    "for key in test_acc.keys():\n",
    "    new_dict[int(key)]=test_acc[key]\n",
    "sorted_dict = dict(sorted(new_dict.items()))\n",
    "\n",
    "# Convert the dictionary to a format suitable for plotting\n",
    "x_values = np.sort([int(key) for key in sorted_dict.keys()])  # Convert keys to integers\n",
    "\n",
    "# For every model, make line plot\n",
    "for i, model in enumerate(models):\n",
    "    \n",
    "    # The accuracy values for increasing number of samples\n",
    "    y_values = [value[i] for value in sorted_dict.values()]\n",
    "\n",
    "    # Create a line plot\n",
    "    plt.plot(x_values, y_values, marker='.', linestyle='-', label=names[i])\n",
    "    \n",
    "# Plot graphics\n",
    "plt.xlabel('Input dimension')\n",
    "plt.ylabel('Training set size')\n",
    "plt.title(f'Training set size required to reach {epsilon} test accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a6a808",
   "metadata": {},
   "source": [
    "1. [Why Are Convolutional Nets More Sample-Efficient than Fully-Connected Nets?](https://arxiv.org/abs/2010.08515) Zhiyuan Li, Yi Zhang, Sanjeev Arora, 2021"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
